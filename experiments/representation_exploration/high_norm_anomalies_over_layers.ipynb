{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sdhelper import SD\n",
    "from PIL import Image\n",
    "import torch\n",
    "from tqdm.autonotebook import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import random\n",
    "\n",
    "torch.set_float32_matmul_precision('high')  # for better performance (got a warning without this during torch compile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = load_dataset(\"0jl/NYUv2\", trust_remote_code=True, split=\"train\")\n",
    "# up1_anomalies = np.load(\"../other/data_labeler/high_norm_anomalies_nyuv2_norm_step50_seed42.npy\")\n",
    "\n",
    "data = load_dataset(\"JonasLoos/imagenet_subset\", split=\"train\")\n",
    "up1_anomalies = np.load(\"../data/data_labeler/high_norm_anomalies_imagenet_subset_step50_seed42_heavy_only.npy\")\n",
    "convin_anomalies = np.load(\"../data/data_labeler/high_norm_anomalies_imagenet_subset_step50_seed42_conv_in.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_blocks_separated = [[\n",
    "        'conv_in',\n",
    "    ],[\n",
    "        'down_blocks[0].resnets[0]',\n",
    "        'down_blocks[0].attentions[0]',\n",
    "        'down_blocks[0].resnets[1]',\n",
    "        'down_blocks[0].attentions[1]',\n",
    "        'down_blocks[0].downsamplers[0]',\n",
    "    ],[\n",
    "        'down_blocks[1].resnets[0]',\n",
    "        'down_blocks[1].attentions[0]',\n",
    "        'down_blocks[1].resnets[1]',\n",
    "        'down_blocks[1].attentions[1]',\n",
    "        'down_blocks[1].downsamplers[0]',\n",
    "    ],[\n",
    "        'down_blocks[2].resnets[0]',\n",
    "        'down_blocks[2].attentions[0]',\n",
    "        'down_blocks[2].resnets[1]',\n",
    "        'down_blocks[2].attentions[1]',\n",
    "        'down_blocks[2].downsamplers[0]',\n",
    "    ],[\n",
    "        'down_blocks[3].resnets[0]',\n",
    "        'down_blocks[3].resnets[1]',\n",
    "    ],[\n",
    "        'mid_block.resnets[0]',\n",
    "        'mid_block.attentions[0]',\n",
    "        'mid_block.resnets[1]',\n",
    "    ],[\n",
    "        'up_blocks[0].resnets[0]',\n",
    "        'up_blocks[0].resnets[1]',\n",
    "        'up_blocks[0].upsamplers[0]',\n",
    "    ],[\n",
    "        'up_blocks[1].resnets[0]',\n",
    "        'up_blocks[1].attentions[0]',\n",
    "        'up_blocks[1].resnets[1]',\n",
    "        'up_blocks[1].attentions[1]',\n",
    "        'up_blocks[1].resnets[2]',\n",
    "        'up_blocks[1].attentions[2]',\n",
    "        'up_blocks[1].upsamplers[0]',\n",
    "    ],[\n",
    "        'up_blocks[2].resnets[0]',\n",
    "        'up_blocks[2].attentions[0]',\n",
    "        'up_blocks[2].resnets[1]',\n",
    "        'up_blocks[2].attentions[1]',\n",
    "        'up_blocks[2].resnets[2]',\n",
    "        'up_blocks[2].attentions[2]',\n",
    "        'up_blocks[2].upsamplers[0]',\n",
    "    ],[\n",
    "        'up_blocks[3].resnets[0]',\n",
    "        'up_blocks[3].attentions[0]',\n",
    "        'up_blocks[3].resnets[1]',\n",
    "        'up_blocks[3].attentions[1]',\n",
    "        'up_blocks[3].resnets[2]',\n",
    "        'up_blocks[3].attentions[2]',\n",
    "    ],[\n",
    "        'conv_out',\n",
    "    ]\n",
    "]\n",
    "all_blocks = [b for blocks_list in all_blocks_separated for b in blocks_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = SD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blocks = [\n",
    "#     'up_blocks[0].upsamplers[0]',\n",
    "#     'up_blocks[1].resnets[0]',\n",
    "#     'up_blocks[1].attentions[0]',\n",
    "#     'up_blocks[1].resnets[1]',\n",
    "#     'up_blocks[1].attentions[1]',\n",
    "#     'up_blocks[1].resnets[2]',\n",
    "#     'up_blocks[1].attentions[2]',\n",
    "#     'up_blocks[1].upsamplers[0]',\n",
    "#     'up_blocks[2].resnets[0]',\n",
    "#     'up_blocks[2].attentions[0]',\n",
    "#     'up_blocks[2].resnets[1]',\n",
    "#     'up_blocks[2].attentions[1]',\n",
    "#     'up_blocks[2].resnets[2]',\n",
    "#     'up_blocks[2].attentions[2]',\n",
    "#     'up_blocks[2].upsamplers[0]',\n",
    "#     'up_blocks[3].resnets[0]',\n",
    "#     'up_blocks[3].attentions[0]',\n",
    "#     'up_blocks[3].resnets[1]',\n",
    "#     'up_blocks[3].attentions[1]',\n",
    "#     'up_blocks[3].resnets[2]',\n",
    "#     'up_blocks[3].attentions[2]',\n",
    "# ]\n",
    "blocks = all_blocks\n",
    "representations_raw = sd.img2repr([x['image'] for x in data], extract_positions=blocks, step=50, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up1_anomaly_norms = np.zeros((len(blocks),len(up1_anomalies)))\n",
    "convin_anomaly_norms = np.zeros((len(blocks),len(convin_anomalies)))\n",
    "corner_norms = np.zeros((len(blocks),len(representations_raw)))\n",
    "border_norms = np.zeros((len(blocks),len(representations_raw)))\n",
    "mean_norms = np.zeros((len(blocks),len(representations_raw)))\n",
    "\n",
    "for j, tmp in enumerate(tqdm(up1_anomalies)):\n",
    "    img_idx, w_idx, h_idx = tmp.tolist()\n",
    "    for i, block in enumerate(blocks):\n",
    "        repr = representations_raw[img_idx][block].squeeze(0).to(dtype=torch.float32)\n",
    "        features, h, w = repr.shape\n",
    "        norms = repr.norm(dim=0)\n",
    "\n",
    "        # up1 anomaly\n",
    "        h_up1 = representations_raw[0]['up_blocks[1].upsamplers[0]'].shape[2]\n",
    "        scale = h / h_up1\n",
    "        h_idx_scaled = int(h_idx*scale)\n",
    "        w_idx_scaled = int(w_idx*scale)\n",
    "        offset = int(2*scale)\n",
    "        if offset < 1: offset = 1\n",
    "        reprs_anomaly = repr[:,h_idx_scaled:h_idx_scaled+offset, w_idx_scaled:w_idx_scaled+offset]\n",
    "        # rel_norm = reprs_anomaly.norm(dim=0)[0,0] / norms.mean()\n",
    "        rel_norm = reprs_anomaly.norm(dim=0).mean() / norms.mean()\n",
    "        up1_anomaly_norms[i,j] = rel_norm.item()\n",
    "\n",
    "for j, tmp in enumerate(tqdm(convin_anomalies)):\n",
    "    img_idx, w_idx, h_idx = tmp.tolist()\n",
    "    for i, block in enumerate(blocks):\n",
    "        repr = representations_raw[img_idx][block].squeeze(0).to(dtype=torch.float32)\n",
    "        features, h, w = repr.shape\n",
    "        norms = repr.norm(dim=0)\n",
    "\n",
    "        # convin anomaly\n",
    "        h_convin = representations_raw[0]['conv_in'].shape[2]\n",
    "        scale = h / h_convin\n",
    "        h_idx_scaled = int(h_idx*scale)\n",
    "        w_idx_scaled = int(w_idx*scale)\n",
    "        reprs_anomaly = repr[:,h_idx_scaled, w_idx_scaled]\n",
    "        rel_norm = reprs_anomaly.norm(dim=0) / norms.mean()\n",
    "        convin_anomaly_norms[i,j] = rel_norm.item()\n",
    "\n",
    "for j in trange(len(representations_raw)):\n",
    "    for i, block in enumerate(blocks):\n",
    "        repr = representations_raw[j][block].squeeze(0).to(dtype=torch.float32)\n",
    "        features, h, w = repr.shape\n",
    "        norms = repr.norm(dim=0)\n",
    "\n",
    "        # mean norm\n",
    "        mean_norms[i,j] = norms.mean().item()\n",
    "\n",
    "        # corner norm\n",
    "        corner_norms[i,j] = norms[[0,0,1,1], [0,1,0,1]].mean().item() / norms.mean()\n",
    "\n",
    "        # border norm\n",
    "        border_norms[i,j] = torch.cat([norms[0,:], norms[-1,:], norms[:,0], norms[:,-1]]).mean().item() / norms.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10,4))\n",
    "\n",
    "# up[1] anomaly\n",
    "plt.fill_between(range(len(blocks)), \n",
    "                 up1_anomaly_norms.mean(axis=1) - up1_anomaly_norms.std(axis=1),\n",
    "                 up1_anomaly_norms.mean(axis=1) + up1_anomaly_norms.std(axis=1), \n",
    "                 alpha=0.2)\n",
    "plt.plot(range(len(blocks)), up1_anomaly_norms.mean(axis=1), label='up[1] anomalies')\n",
    "\n",
    "# conv-in anomaly\n",
    "plt.fill_between(range(len(blocks)),\n",
    "                 convin_anomaly_norms.mean(axis=1) - convin_anomaly_norms.std(axis=1),\n",
    "                 convin_anomaly_norms.mean(axis=1) + convin_anomaly_norms.std(axis=1),\n",
    "                 alpha=0.2) \n",
    "plt.plot(range(len(blocks)), convin_anomaly_norms.mean(axis=1), label='conv-in anomalies')\n",
    "\n",
    "# corner norm\n",
    "# plt.fill_between(range(len(blocks)),\n",
    "#                  corner_norms.mean(axis=1) - corner_norms.std(axis=1),\n",
    "#                  corner_norms.mean(axis=1) + corner_norms.std(axis=1),\n",
    "#                  alpha=0.2, label='corner') \n",
    "# plt.plot(range(len(blocks)), corner_norms.mean(axis=1))\n",
    "\n",
    "# border norm\n",
    "# plt.fill_between(range(len(blocks)),\n",
    "#                  border_norms.mean(axis=1) - border_norms.std(axis=1),\n",
    "#                  border_norms.mean(axis=1) + border_norms.std(axis=1),\n",
    "#                  alpha=0.2, label='border') \n",
    "# plt.plot(range(len(blocks)), border_norms.mean(axis=1))\n",
    "\n",
    "# mean norm\n",
    "plt.plot(range(len(blocks)), np.ones(len(blocks)), color='black', linestyle='--', label='all')\n",
    "\n",
    "plt.title(\"Relative norm of anomaly over layers\")\n",
    "plt.ylabel(\"mean norm relative to all\")\n",
    "\n",
    "# plot x ticks\n",
    "x = np.arange(len(blocks))\n",
    "ticks = ['attn' if 'attentions' in block else 'res' if 'resnets' in block else 'down' if 'downsamplers' in block else 'up' if 'upsamplers' in block else 'conv' if 'conv' in block else '?' for block in blocks]\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(ticks, rotation=90)\n",
    "\n",
    "# compute main blocks names and positions\n",
    "main_blocks = []\n",
    "main_block_positions = []\n",
    "tmp = 0\n",
    "for block_list in all_blocks_separated:\n",
    "    if 'mid' in block_list[0]:\n",
    "        name = 'mid'\n",
    "    elif 'conv' in block_list[0]:\n",
    "        name = block_list[0][5:]\n",
    "    else:\n",
    "        a, b, *_ = block_list[0].split('[')\n",
    "        name = a.replace('_blocks','') + b.split(']')[0]\n",
    "    main_blocks.append(name)\n",
    "    main_block_positions.append(tmp)\n",
    "    tmp += len(block_list)\n",
    "\n",
    "# lines between main blocks\n",
    "for p in main_block_positions[1:]:\n",
    "    ax1.axvline(x=p-0.5, color='black', linestyle='--', c='lightgray')\n",
    "ax_x3 = ax1.secondary_xaxis(location=0)\n",
    "ax_x3.set_xticks([p-0.5 for p in main_block_positions[1:]], labels=[])\n",
    "ax_x3.tick_params(axis='x', length=34, width=1.5, color='lightgray')\n",
    "\n",
    "ax_x2 = ax1.secondary_xaxis(location=0)\n",
    "ax_x2.set_xticks([p+len(bl)/2-0.5 for p, bl in zip(main_block_positions, all_blocks_separated)], labels=[f'\\n\\n\\n{b}' for b in main_blocks], ha='center')\n",
    "ax_x2.tick_params(length=0)\n",
    "\n",
    "ax1.legend()\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_yticks([0.5, 1.0, 2.0, 4.0])\n",
    "ax1.set_yticklabels([f'{x:.1f}' for x in ax1.get_yticks()])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "img_idx, w_idx, h_idx = random.choice(convin_anomalies).tolist()\n",
    "plt.imshow(representations_raw[img_idx]['conv_in'].squeeze(0).to(dtype=torch.float32).norm(dim=0))\n",
    "plt.scatter(w_idx, h_idx, color='red')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
