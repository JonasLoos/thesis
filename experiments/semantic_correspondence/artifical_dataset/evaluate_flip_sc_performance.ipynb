{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate flip semantic/dense correspondence performance\n",
    "\n",
    "WIP: is the normalization factor good?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from sdhelper import SD\n",
    "import torch\n",
    "from tqdm.autonotebook import tqdm, trange\n",
    "import PIL.Image\n",
    "import PIL.ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = Path('../../random_images_flux')\n",
    "images = [PIL.Image.open(img) for img in list(img_path.glob('*.jpg'))]\n",
    "sd = SD('sd15', disable_progress_bar=True)\n",
    "reprs = [sd.img2repr(img, extract_positions=sd.available_extract_positions, step=50) for img in tqdm(images, desc='extracting representations')]\n",
    "reprs_flipped = [sd.img2repr(PIL.ImageOps.mirror(img), extract_positions=sd.available_extract_positions, step=50) for img in tqdm(images, desc='extracting representations')]\n",
    "del sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate error as in show_flip_sc_fails.ipynb and average it over each image\n",
    "\n",
    "num_positions = len(reprs[0].data)\n",
    "fig = plt.figure(figsize=(12, 3*num_positions))\n",
    "\n",
    "gs = fig.add_gridspec(num_positions, 2, width_ratios=[2, 1], hspace=0.4, wspace=0.3)\n",
    "errors = np.zeros((len(images), num_positions))\n",
    "\n",
    "for idx, p in enumerate(tqdm(reprs[0].data, desc='calculating errors')):\n",
    "    n = reprs[0].data[p].shape[-1]\n",
    "\n",
    "    for i, (repr, repr_flipped) in enumerate(zip(reprs, reprs_flipped)):\n",
    "        similarities = repr.at(p).cosine_similarity(repr_flipped.at(p))\n",
    "\n",
    "        indices = similarities.view(-1, n, n).argmax(dim=0)\n",
    "        k_, l_ = indices // n, indices % n\n",
    "        l_ = n - 1 - l_  # flip\n",
    "\n",
    "        k, l = torch.meshgrid(torch.arange(n), torch.arange(n), indexing='ij')\n",
    "        dist = ((k - k_)**2 + (l - l_)**2).sqrt()\n",
    "\n",
    "        max_possible_dist = ((n-1)**2 + (n-1)**2)**0.5\n",
    "        errors[i, idx] = (dist / max_possible_dist).mean()\n",
    "\n",
    "    # Error distribution plot\n",
    "    ax_dist = fig.add_subplot(gs[idx, 0])\n",
    "    ax_dist.hist(errors[:, idx], bins=20, color='skyblue', edgecolor='black')\n",
    "    ax_dist.set_title(f'Error Distribution for {p}')\n",
    "    ax_dist.set_xlabel('Error')\n",
    "    ax_dist.set_ylabel('Frequency')\n",
    "\n",
    "    # Violin plot\n",
    "    ax_violin = fig.add_subplot(gs[idx, 1])\n",
    "    ax_violin.violinplot(errors[:, idx], showmeans=True, showextrema=True, showmedians=True)\n",
    "    ax_violin.set_title(f'Error Violin Plot for {p}')\n",
    "    ax_violin.set_ylabel('Error')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_visualization(image, repr, repr_flipped):\n",
    "    # Calculate similarities and indices\n",
    "    similarities = repr.cosine_similarity(repr_flipped)\n",
    "    n = similarities.shape[-1]\n",
    "    indices = similarities.view(-1, n, n).argmax(dim=0)\n",
    "    k_, l_ = indices // n, indices % n\n",
    "    l_ = n - 1 - l_  # flip\n",
    "\n",
    "    # Calculate distance\n",
    "    k, l = torch.meshgrid(torch.arange(n), torch.arange(n), indexing='ij')\n",
    "    dist = ((k - k_)**2 + (l - l_)**2).sqrt()\n",
    "\n",
    "    # Create error normalization helper matrix\n",
    "    tmp = torch.arange(-n, n).unsqueeze(0)**2\n",
    "    error_normalization_matrix = torch.cumsum(torch.cumsum((tmp + tmp.T).sqrt(), dim=1), dim=0)\n",
    "\n",
    "    # Normalize distance\n",
    "    x_start, y_start = n - k - 1, n-l - 1\n",
    "    x_end, y_end = x_start + n, y_start + n\n",
    "    normalizer = (error_normalization_matrix[x_end,y_end] + error_normalization_matrix[x_start,y_start] - \n",
    "                  error_normalization_matrix[x_end,y_start] - error_normalization_matrix[x_start,y_end]) / n\n",
    "    normalized_dist = dist / normalizer\n",
    "\n",
    "    # Create the plot\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(7.5, 3))\n",
    "    ax1.imshow(image)\n",
    "    ax1.axis('off')\n",
    "    ax1.set_title('Original Image')\n",
    "    im = ax2.imshow(normalized_dist, cmap='YlOrRd', interpolation='nearest', aspect='equal')\n",
    "    ax2.axis('off')\n",
    "    ax2.set_title('Error Visualization')\n",
    "    fig.colorbar(im, ax=ax2, label='Normalized Error')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Ensure both subplots have the same size and are well-aligned\n",
    "    ax1_pos = ax1.get_position()\n",
    "    ax2_pos = ax2.get_position()\n",
    "    ax2.set_position([ax2_pos.x0, ax1_pos.y0, ax2_pos.width, ax1_pos.height])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# plot highest and lowest error images\n",
    "pos_idx = list(reprs[0].data.keys()).index('up_blocks[1]')\n",
    "for error_type, error_func in [(\"highest\", np.argmax), (\"lowest\", np.argmin)]:\n",
    "    error_index = error_func(errors[:, pos_idx]).item()\n",
    "    print(f\"Image with {error_type} average error (id: {error_index}): {errors[error_index, pos_idx]:.4f}\")\n",
    "    plot_error_visualization(images[error_index], reprs[error_index], reprs_flipped[error_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_normalizer(n):\n",
    "    k, l = torch.meshgrid(torch.arange(n), torch.arange(n), indexing='ij')\n",
    "\n",
    "    # Create error normalization helper matrix\n",
    "    tmp = torch.arange(-n, n).unsqueeze(0)**2\n",
    "    error_normalization_matrix = torch.cumsum(torch.cumsum((tmp + tmp.T).sqrt(), dim=1), dim=0)\n",
    "\n",
    "    # Normalize distance\n",
    "    x_start, y_start = n - k - 1, n-l - 1\n",
    "    x_end, y_end = x_start + n, y_start + n\n",
    "    normalizer = (error_normalization_matrix[x_end,y_end] + error_normalization_matrix[x_start,y_start] - \n",
    "                    error_normalization_matrix[x_end,y_start] - error_normalization_matrix[x_start,y_end]) / n\n",
    "\n",
    "    # Plot the normalizer\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(normalizer.numpy(), cmap='plasma')\n",
    "    plt.colorbar(label='Normalization Factor')\n",
    "    plt.title('Normalizer')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.show()\n",
    "\n",
    "plot_normalizer(reprs[0].data['up_blocks[1]'].shape[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
