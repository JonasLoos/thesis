{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdhelper import SD\n",
    "import torch\n",
    "import numpy as np\n",
    "import datasets\n",
    "from tqdm.autonotebook import tqdm, trange\n",
    "from matplotlib import pyplot as plt\n",
    "import PIL.Image\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and dataset\n",
    "sd = SD('SD1.5')\n",
    "data = datasets.load_dataset('0jl/SPair-71k', 'data', split='train', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "pos = ['down_blocks[3]', 'mid_block', 'up_blocks[0]', 'up_blocks[1]', 'up_blocks[2]']\n",
    "img_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precalculate representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precalculate representations\n",
    "\n",
    "def expand_and_resize(x: PIL.Image.Image, size = img_size, border_pad=True):\n",
    "    n, m = x.size\n",
    "    s = max(n, m)\n",
    "    r = PIL.Image.new('RGB', (s, s))\n",
    "    r.paste(x, ((s-n)//2, (s-m)//2))\n",
    "    if border_pad:\n",
    "        # pad with border\n",
    "        if n > m:\n",
    "            r.paste(x.crop((0, 0, n, 1)).resize((n,(s-m)//2)), (0, 0))\n",
    "            r.paste(x.crop((0, m-1, n, m)).resize((n,(s-m)//2)), (0, m+(s-m)//2))\n",
    "        elif m > n:\n",
    "            r.paste(x.crop((0, 0, 1, m)).resize(((s-n)//2,m)), (0, 0))\n",
    "            r.paste(x.crop((n-1, 0, n, m)).resize(((s-n)//2,m)), (n+(s-n)//2, 0))\n",
    "    return r.resize((size, size))\n",
    "\n",
    "representations = []\n",
    "for x in tqdm(data, desc='Calculating representations'):\n",
    "    r = sd.img2repr(expand_and_resize(x['img']), pos, 100, prompt=x['name'].split('/')[0])\n",
    "    representations.append({p: x[0].permute(1,2,0).flatten(0,1).to(torch.float32) for p, x in r.data.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Layer to estimate position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init linear classification layers\n",
    "linear_layers = []\n",
    "sample_reprs = sd.img2repr(np.zeros((img_size, img_size, 3)), pos, 100)\n",
    "for p in pos:\n",
    "    linear_layers.append(nn.Linear(in_features=sample_reprs[p].shape[1], out_features=sample_reprs[p].shape[2] * sample_reprs[p].shape[3], dtype=torch.float32, device=sd.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = [\n",
    "    torch.optim.Adam(l.parameters(), lr=1e-3) for l in linear_layers\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "for epoch in trange(10):\n",
    "    print(f'Epoch {epoch}')\n",
    "    for i, sample in enumerate(tqdm(representations[:-200], leave=False)):\n",
    "        for p, l, o in zip(pos, linear_layers, optimizers):\n",
    "            x = sample[p].to('cuda')\n",
    "            l.zero_grad()\n",
    "            y = l(x)\n",
    "            loss = nn.functional.cross_entropy(y, torch.arange(y.shape[0], device=sd.device))\n",
    "            loss.backward()\n",
    "            o.step()\n",
    "        if i % 100 == 0:\n",
    "            print(loss.item())\n",
    "    # for sample in tqdm(representations[-200:], leave=False):\n",
    "    #     for p, l in zip(pos, linear_layers):\n",
    "    #         x = sample[p][0].permute(1,2,0).flatten(0,1).to('cuda')\n",
    "    #         y = l(x)\n",
    "    #         loss = nn.functional.cross_entropy(y, torch.arange(y.shape[0], device=sd.device))\n",
    "    #         plot(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "accuracies = {p: [] for p in pos}\n",
    "with torch.no_grad():\n",
    "    for sample in tqdm(representations[-200:]):\n",
    "        for p, l in zip(pos, linear_layers):\n",
    "            x = sample[p].to('cuda')\n",
    "            y = l(x)\n",
    "            accuracies[p].append((y.argmax(dim=1) == torch.arange(y.shape[0], device='cuda')).float().mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p, a in accuracies.items():\n",
    "    print(f'{p:15} {np.mean(a):7.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(linear_layers[2].bias.cpu().detach().numpy().flatten(), bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(linear_layers[2].weight.cpu().detach().numpy().flatten(), bins=100)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Weight value')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(linear_layers[2].weight.cpu().detach().abs().numpy().flatten() > 0.25).sum() / linear_layers[2].weight.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get PCs corresponding to positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pca_basis(data):\n",
    "    # Center the data\n",
    "    data_mean = torch.mean(data, dim=0)\n",
    "    data_centered = data - data_mean\n",
    "\n",
    "    # Compute covariance matrix\n",
    "    covariance_matrix = torch.mm(data_centered.T, data_centered) / (data_centered.size(0) - 1)\n",
    "\n",
    "    # Compute eigenvalues and eigenvectors using torch.linalg.eigh\n",
    "    eigenvalues, eigenvectors = torch.linalg.eigh(covariance_matrix)\n",
    "\n",
    "    # Sort eigenvalues and eigenvectors in descending order\n",
    "    sorted_indices = torch.argsort(eigenvalues, descending=True)\n",
    "    sorted_eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "    return sorted_eigenvectors, data_mean\n",
    "\n",
    "\n",
    "def transform_data(data, pca_basis, data_mean):\n",
    "    data_centered = data - data_mean\n",
    "    transformed_data = torch.mm(data_centered, pca_basis)\n",
    "    return transformed_data\n",
    "\n",
    "\n",
    "# pca transform\n",
    "for p in tqdm(pos):\n",
    "    print(f'calculating PCA basis for {p}')\n",
    "    num_features = representations[0][p].shape[1]\n",
    "    pca_basis, data_mean = compute_pca_basis(torch.cat([r[p] for r in representations[:-200]], dim=1).T)\n",
    "    print('finding PCs corresponding to directions')\n",
    "    representations_pca = torch.stack([transform_data(r[p].T, pca_basis, data_mean) for r in representations])\n",
    "\n",
    "    # calc. correlation between all dimensions (PCs) and positions for whole (test) dataset\n",
    "    representations_pca = representations_pca / representations_pca.pow(2).sum(dim=2, keepdim=True).sqrt()\n",
    "    n = int(representations_pca.shape[2] ** 0.5)\n",
    "    positions = torch.arange(n) - (n/2 - 0.5)\n",
    "    positions /= positions.pow(2).sum().sqrt()\n",
    "    y_correlations = (representations_pca * positions.repeat_interleave(n)[None, None, :]).sum(dim=2).mean(dim=0)\n",
    "    x_correlations = (representations_pca * positions.repeat(n)[None, None, :]).sum(dim=2).mean(dim=0)\n",
    "    y_sorted_idx =  y_correlations.abs().argsort(descending=True)\n",
    "    x_sorted_idx =  x_correlations.abs().argsort(descending=True)\n",
    "    print(f'Y best: {y_correlations[y_sorted_idx[0]]:+.4f} at PC {y_sorted_idx[0]:4}, top 10: {\", \".join(f\"{y:+.2f}\" for y in y_correlations[y_sorted_idx[:10]])}')\n",
    "    print(f'X best: {x_correlations[x_sorted_idx[0]]:+.4f} at PC {x_sorted_idx[0]:4}, top 10: {\", \".join(f\"{x:+.2f}\" for x in x_correlations[x_sorted_idx[:10]])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "representations_pca.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
