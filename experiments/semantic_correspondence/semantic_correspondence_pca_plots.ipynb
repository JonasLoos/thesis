{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdhelper import SD\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "from transformers import SamModel, SamProcessor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "from semantic_correspondence import expand_and_resize, expand, concat_reprs\n",
    "from PIL import Image\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "sd = SD('SDXL')\n",
    "sam_model = SamModel.from_pretrained(\"facebook/sam-vit-base\").to(\"cuda\")\n",
    "sam_processor = SamProcessor.from_pretrained(\"facebook/sam-vit-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "pairs = load_dataset('0jl/SPair-71k')\n",
    "img_data = load_dataset('0jl/SPair-71k', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test SAM model\n",
    "i = 0\n",
    "raw_image = img_data['train'][i]['img']\n",
    "input_points = [[json.loads(img_data['train'][i]['annotation'])['kps']['0']]] # 2D localization of a window\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = sam_processor(raw_image, input_points=input_points, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = sam_model(**inputs)\n",
    "    masks = sam_processor.image_processor.post_process_masks(outputs.pred_masks.cpu(), inputs[\"original_sizes\"].cpu(), inputs[\"reshaped_input_sizes\"].cpu())\n",
    "    scores = outputs.iou_scores\n",
    "print(f'IOU score: {scores[0][0].cpu()}')\n",
    "print(f'Found {len(masks[0])} masks')\n",
    "print(f'Predicted mask shape: {masks[0][0].shape}')\n",
    "\n",
    "mask = Image.fromarray((masks[0][0].permute(1,2,0).detach().cpu().numpy().sum(axis=2)>0).astype(np.uint8)*255)\n",
    "mask = mask.resize((mask.size[0]//8, mask.size[1]//8))\n",
    "mask = np.array(mask) > 0\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(mask, cmap='gray')\n",
    "plt.scatter(input_points[0][0][0]/8, input_points[0][0][1]/8, c='r')\n",
    "plt.axis('off')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(raw_image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca(imgs: list, pos = ['up_blocks[1]'], step = 50, size = 512, segmentations = None):\n",
    "    imgs_expanded = [expand(img, size) for img in imgs]\n",
    "    reprs_ = [concat_reprs(sd.img2repr(img, pos, step), pos) for img in imgs_expanded]\n",
    "    reprs = [repr.reshape(repr.shape[0], -1).T for repr in reprs_]\n",
    "    pca = PCA(n_components=3)\n",
    "    pca.fit(torch.cat(reprs, 0).numpy())\n",
    "    pcas = [pca.transform(repr) for repr in reprs]\n",
    "    pca_min = min([pca.min() for pca in pcas])\n",
    "    pcas = [pca - pca_min for pca in pcas]\n",
    "    pca_max = max([pca.max() for pca in pcas])\n",
    "    pcas = [pca / pca_max for pca in pcas]\n",
    "    masked_reprs = []\n",
    "    if segmentations is not None:\n",
    "        masks = [np.array(segmentation.resize((repr.shape[2], repr.shape[1]))) for segmentation, repr in zip(segmentations, reprs_)]\n",
    "        for repr, mask in zip(reprs_, masks):\n",
    "            masked_repr = np.array([repr[:,i,j] for i, j in np.argwhere(mask)])\n",
    "            masked_reprs.append(masked_repr)\n",
    "        pca2 = PCA(n_components=3)\n",
    "        pca2.fit(np.concatenate(masked_reprs, 0))\n",
    "        pcas2 = [pca2.transform(masked_repr) for masked_repr in masked_reprs]\n",
    "        pca_min = min([pca.min() for pca in pcas2])\n",
    "        pcas2 = [pca - pca_min for pca in pcas2]\n",
    "        pca_max = max([pca.max() for pca in pcas2])\n",
    "        pcas2 = [pca / pca_max for pca in pcas2]\n",
    "\n",
    "    fig, ax = plt.subplots(2 + (segmentations is not None), len(imgs), squeeze=False, figsize=(len(imgs)*5, 10))\n",
    "    for i, img in enumerate(imgs):\n",
    "        ax[0, i].imshow(img)\n",
    "        ax[1, i].imshow(pcas[i].reshape(*reprs_[i].shape[1:],3)[:,:,:])\n",
    "        ax[0, i].axis('off')\n",
    "        ax[1, i].axis('off')\n",
    "        if segmentations is not None:\n",
    "            mask = masks[i]\n",
    "            tmp = np.zeros((*mask.shape,3))\n",
    "            for (u,v), x in zip(np.argwhere(mask), pcas2[i]):\n",
    "                tmp[u,v,:] = x\n",
    "            ax[2, i].imshow(tmp)\n",
    "            ax[2, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for category in pairs['train'].features['category'].names:\n",
    "    imgs = []\n",
    "    segmentations = []\n",
    "    for x in img_data['train']:\n",
    "        an = json.loads(x['annotation'])\n",
    "        if an['category'] == category:\n",
    "            imgs.append(x['img'])\n",
    "\n",
    "            # get segmentation using SAM\n",
    "            # with torch.no_grad():\n",
    "            #     kp = [kp for kp in an['kps'].values() if kp is not None][0]\n",
    "            #     inputs = sam_processor(x['img'], input_points=[[kp]], return_tensors=\"pt\").to(\"cuda\")\n",
    "            #     outputs = sam_model(**inputs)\n",
    "            #     masks = sam_processor.image_processor.post_process_masks(outputs.pred_masks.cpu(), inputs[\"original_sizes\"].cpu(), inputs[\"reshaped_input_sizes\"].cpu())\n",
    "            # mask = Image.fromarray((masks[0][0].permute(1,2,0).detach().cpu().numpy().sum(axis=2)>0).astype(np.uint8)*255)\n",
    "            # segmentations.append(mask)\n",
    "\n",
    "            # get given segmentation\n",
    "            segmentations.append(x['segmentation'])\n",
    "\n",
    "        if len(imgs) == 6:\n",
    "            break\n",
    "\n",
    "    plot_pca(imgs, ['up_blocks[0]', 'up_blocks[1]'], 50, 1024, segmentations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check segmentations\n",
    "for _ in range(4):\n",
    "    i = random.randint(0, len(img_data['train']))\n",
    "    x = img_data['train'][i]\n",
    "    seg = x['segmentation']\n",
    "    print(np.array(seg).shape)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(np.array(seg)>0)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(x['img'])\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
