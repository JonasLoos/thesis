{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Correspondence - embedding due to positional embedding\n",
    "\n",
    "Semantic correspondence on SPair-71k and tests on the influence of the source kp position on failures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdhelper import SD\n",
    "import torch\n",
    "import numpy as np\n",
    "import datasets\n",
    "from tqdm.autonotebook import tqdm, trange\n",
    "from matplotlib import pyplot as plt\n",
    "import PIL.Image\n",
    "from typing import Callable\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from typing import Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = SD('SD1.5')\n",
    "data = datasets.load_dataset('0jl/SPair-71k', 'data', split='train', trust_remote_code=True)\n",
    "pairs = datasets.load_dataset('0jl/SPair-71k', 'pairs', split='test', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_keys = ['src_bndbox','trg_bndbox','category','viewpoint_variation','scale_variation',]\n",
    "metadata = [{'i': i, 'src_kp': src_kp, 'trg_kp': trg_kp, 'src_size': pair['src_img'].size, 'trg_size': pair['trg_img'].size} | {k: pair[k] for k in metadata_keys} for i, pair in enumerate(tqdm(pairs)) for src_kp, trg_kp in zip(pair['src_kps'], pair['trg_kps'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate semantic correspondence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_and_resize(x: PIL.Image.Image, size, border_pad=True):\n",
    "    n, m = x.size\n",
    "    s = max(n, m)\n",
    "    r = PIL.Image.new('RGB', (s, s))\n",
    "    r.paste(x, ((s-n)//2, (s-m)//2))\n",
    "    if border_pad:\n",
    "        # pad with border\n",
    "        if n > m:\n",
    "            r.paste(x.crop((0, 0, n, 1)).resize((n,(s-m)//2)), (0, 0))\n",
    "            r.paste(x.crop((0, m-1, n, m)).resize((n,(s-m)//2)), (0, m+(s-m)//2))\n",
    "        elif m > n:\n",
    "            r.paste(x.crop((0, 0, 1, m)).resize(((s-n)//2,m)), (0, 0))\n",
    "            r.paste(x.crop((n-1, 0, n, m)).resize(((s-n)//2,m)), (n+(s-n)//2, 0))\n",
    "    return r.resize((size, size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_expanded = [expand_and_resize(x['img'], 512, True) for x in tqdm(data, desc='Expanding images')]\n",
    "prompts = [x['name'].split('/')[0] for x in data]\n",
    "representations_raw = sd.img2repr(images_expanded, ['up_blocks[1]'], 50, seed=42)\n",
    "representations = [r.apply(lambda x: x / torch.norm(x, dim=0, keepdim=True)) for r in tqdm(representations_raw, desc='Normalizing representations')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate percentage of correct keypoints at 10% of the bounding box (PCK@0.1_bbox)\n",
    "correct = []\n",
    "positions = []\n",
    "for x in (t:=tqdm(pairs, desc='Calculating SC')):\n",
    "    a = representations[x['src_data_index']].concat()\n",
    "    b = representations[x['trg_data_index']].concat()\n",
    "    tbb_max = max(x['trg_bndbox'][2] - x['trg_bndbox'][0], x['trg_bndbox'][3] - x['trg_bndbox'][1])\n",
    "    for ([sx, sy],[tx,ty]) in zip(x['src_kps'], x['trg_kps']):\n",
    "        src_repr = a[:, \n",
    "            int((sy + (max(x['src_img'].size) - x['src_img'].size[1])/2) * a.shape[1] / max(x['src_img'].size)),\n",
    "            int((sx + (max(x['src_img'].size) - x['src_img'].size[0])/2) * a.shape[2] / max(x['src_img'].size)),\n",
    "        ]\n",
    "        cossim = (b * src_repr[:,None,None]).sum(dim=0)\n",
    "        y_max, x_max = np.unravel_index(cossim.argmax().cpu(), cossim.shape)\n",
    "        x_max_pixel = x_max / b.shape[2] * max(x['trg_img'].size) - (max(x['trg_img'].size) - x['trg_img'].size[0]) / 2\n",
    "        y_max_pixel = y_max / b.shape[1] * max(x['trg_img'].size) - (max(x['trg_img'].size) - x['trg_img'].size[1]) / 2\n",
    "        relative_distance = ((x_max_pixel - tx)**2 + (y_max_pixel - ty)**2) ** 0.5 / tbb_max\n",
    "        correct.append(relative_distance < 0.1)\n",
    "        positions.append((x_max_pixel, y_max_pixel))\n",
    "    if len(correct) % 100 == 0:\n",
    "        t.set_postfix(pck=np.mean(correct)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(correct)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_failures(f: Callable[['Any'], tuple[int,int]]):\n",
    "    fail_distances = defaultdict(int)\n",
    "    for tmp, (x,y) in zip(metadata, positions):\n",
    "        x0, y0 = f(tmp)\n",
    "        dist = np.hypot(x0-x, y0-y)\n",
    "        fail_distances[dist**2//25] += 1\n",
    "    fail_distances = sorted(fail_distances.items())\n",
    "    x = []\n",
    "    y = []\n",
    "    for tmp, count in fail_distances:\n",
    "        # if ((tmp+1)*25)**.5 < 20:\n",
    "        #     print(f'until {((tmp+1)*25)**.5:2.0f} pixels: {count} keypoints')\n",
    "        x.append(((tmp+1)*25)**.5)\n",
    "        y.append(count/np.pi/25)\n",
    "    plt.scatter(x, y, s=2, alpha=0.5)\n",
    "    plt.xlabel('Distance to source keypoint (pixels)')\n",
    "    plt.ylabel('Number of failed keypoints per pixel')\n",
    "\n",
    "plt.xlim(0, 200)\n",
    "plot_failures(lambda x: (x['src_kp'][0], x['src_kp'][1]))\n",
    "plot_failures(lambda x: (random.randint(100,400), random.randint(100,300)))\n",
    "plt.legend(['Source KP', 'Random KP'])\n",
    "plt.title('Distance of failed keypoint guess to source keypoint')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_failures(f: Callable[[Any], tuple[int,int]], only_fails=False):\n",
    "    fail_distances = defaultdict(int)\n",
    "    for c, tmp, (x,y) in zip(correct, metadata, positions):\n",
    "        if only_fails and c:\n",
    "            continue\n",
    "        x0, y0 = f(tmp)\n",
    "        dist = np.hypot(x0-x, y0-y)\n",
    "        fail_distances[dist**2//25] += 1\n",
    "    fail_distances = sorted(fail_distances.items())\n",
    "    num_fails = sum(val for key, val in fail_distances)\n",
    "    x = []\n",
    "    y = []\n",
    "    for tmp, count in fail_distances:\n",
    "        # if ((tmp+1)*25)**.5 < 20:\n",
    "        #     print(f'until {((tmp+1)*25)**.5:2.0f} pixels: {count} keypoints')\n",
    "        x.append(((tmp+1)*25)**.5)\n",
    "        y.append(count/np.pi/25 / num_fails)\n",
    "    plt.scatter(x, y, s=2, alpha=0.5)\n",
    "    plt.xlabel('Distance to source keypoint (pixels)')\n",
    "    plt.ylabel('Normalized number of failed keypoints per pixel')\n",
    "\n",
    "plt.xlim(0, 200)\n",
    "plot_failures(lambda x: (x['src_kp'][0], x['src_kp'][1]), only_fails=True)\n",
    "plot_failures(lambda x: (x['src_kp'][0], x['src_kp'][1]))\n",
    "# plot_failures(lambda x: (random.randint(100,400), random.randint(100,300)))\n",
    "plt.legend(['Failed KP', 'All KP'])\n",
    "plt.title('Distance of failed keypoint guess to source keypoint')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# failure distance\n",
    "def plot_failures(f: Callable[[Any,Any,Any], float], only_fails=False):\n",
    "    fail_distances = defaultdict(int)\n",
    "    for c, tmp, (x,y) in zip(correct, metadata, positions):\n",
    "        if only_fails and c:\n",
    "            continue\n",
    "        fail_distances[f(tmp, x, y)//1] += 1\n",
    "    num_fails = sum(val for key, val in fail_distances.items())\n",
    "    x = []\n",
    "    y = []\n",
    "    for tmp, count in sorted(fail_distances.items()):\n",
    "        x.append((tmp+1))\n",
    "        y.append(count/2 / num_fails)\n",
    "    plt.scatter(x, np.array(y), s=3, alpha=0.5)\n",
    "    plt.xlabel('Distance to source keypoint (pixels)')\n",
    "    plt.ylabel('Normalized number of failed keypoints per row/column')\n",
    "\n",
    "# x\n",
    "plt.xlim(0, 200)\n",
    "plot_failures(lambda tmp, x, y: abs(tmp['src_kp'][0] - x), only_fails=True)\n",
    "plot_failures(lambda tmp, x, y: abs(tmp['src_kp'][0] - x))\n",
    "plt.legend(['Failed KP', 'All KP'])\n",
    "plt.title('X-Distance of failed keypoint guess to source keypoint')\n",
    "plt.show()\n",
    "\n",
    "# y\n",
    "plt.xlim(0, 200)\n",
    "plot_failures(lambda tmp, x, y: abs(tmp['src_kp'][1] - y), only_fails=True)\n",
    "plot_failures(lambda tmp, x, y: abs(tmp['src_kp'][1] - y))\n",
    "plt.legend(['Failed KP', 'All KP'])\n",
    "plt.title('Y-Distance of failed keypoint guess to source keypoint')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCK over keypoint distance\n",
    "n = 50\n",
    "distances = {i: [] for i in range(n)}\n",
    "counts = {i: 0 for i in range(n)}\n",
    "for c, m, (x,y) in zip(correct, metadata, positions):\n",
    "    max_size = max(max(m['src_size']), max(m['trg_size']))\n",
    "    dist = np.hypot((m['src_kp'][0] - m['trg_kp'][0]) / max_size, (m['src_kp'][1] - m['trg_kp'][1]) / max_size)\n",
    "    key = int(dist*n)\n",
    "    if key > n-1:\n",
    "        key = n-1\n",
    "    distances[key].append(c)\n",
    "    counts[key] += 1\n",
    "\n",
    "plt.bar(counts.keys(), counts.values(), color='lightblue')\n",
    "plt.ylabel('Number of keypoints', color='lightblue')\n",
    "plt.xlabel('Distance between keypoints (normalized)')\n",
    "plt.xticks(range(0,n,n//10), [f'{i/n:.1f}' for i in range(0,n,n//10)])\n",
    "plt.twinx()\n",
    "plt.plot(distances.keys(), [np.mean(d)*100 for d in distances.values()], 'red')\n",
    "plt.ylabel('PCK@$0.1_{bbox}$ (%)', color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize random failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize random failures\n",
    "i = random.randint(0, len(metadata))\n",
    "while correct[i]:\n",
    "    i = random.randint(0, len(metadata))\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(pairs[metadata[i]['i']]['src_img'])\n",
    "plt.scatter(metadata[i]['src_kp'][0], metadata[i]['src_kp'][1], c='g', marker='x', s=200)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(pairs[metadata[i]['i']]['trg_img'])\n",
    "plt.scatter(metadata[i]['trg_kp'][0], metadata[i]['trg_kp'][1], c='g', marker='x', s=200)\n",
    "plt.scatter(positions[i][0], positions[i][1], c='r', marker='x', s=200)\n",
    "relative_distance = ((positions[i][0] - metadata[i]['trg_kp'][0])**2 + (positions[i][1] - metadata[i]['trg_kp'][1])**2) ** 0.5 / max(metadata[i]['trg_bndbox'][2] - metadata[i]['trg_bndbox'][0], metadata[i]['trg_bndbox'][3] - metadata[i]['trg_bndbox'][1])\n",
    "plt.title(f'PCK@0.1_bbox: {relative_distance:.2f}')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
