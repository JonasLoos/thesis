{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sdhelper import SD\n",
    "from PIL import Image\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from tqdm.autonotebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"high_norm_anomalies_nyuv2_norm_step50_seed42.npy\"\n",
    "seed = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"0jl/NYUv2\", split=\"train\", trust_remote_code=True)\n",
    "dataset[0]['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(data_path)\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.zeros((len(dataset),), dtype=np.int32)\n",
    "for i, x, y in data:\n",
    "    counts[i] += 1\n",
    "\n",
    "bars = np.zeros(counts.max()+1)\n",
    "for x in counts:\n",
    "    bars[x] += 1\n",
    "\n",
    "plt.bar(np.arange(len(bars)), bars)\n",
    "plt.title(\"Number of anomalies per image\")\n",
    "# plt.yscale(\"log\")\n",
    "plt.xlabel(\"Number of anomalies\")\n",
    "plt.ylabel(\"Number of images\")\n",
    "plt.show()\n",
    "\n",
    "print(f'{1-bars[0]/len(dataset):.2%} of images have anomalies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = SD()\n",
    "representations = sd.img2repr([x['image'] for x in dataset], extract_positions=['up_blocks[1]'], step=50, seed=seed)\n",
    "representations = torch.stack([r['up_blocks[1]'].squeeze(0) for r in representations]).to(dtype=torch.float32)\n",
    "norms = torch.linalg.norm(representations, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm histogram\n",
    "norms_of_selected = norms[data[:, 0], data[:, 2], data[:, 1]]\n",
    "print(f'norms of selected: min {norms_of_selected.min():.2f}, max {norms_of_selected.max():.2f}, mean {norms_of_selected.mean():.2f}')\n",
    "\n",
    "# mean norm of 2x2 patches around selected anomalies \n",
    "reprs_of_patches = torch.concat([\n",
    "    representations[data[:, 0], :, data[:, 2]+0, data[:, 1]+0],\n",
    "    representations[data[:, 0], :, data[:, 2]+0, data[:, 1]+1],\n",
    "    representations[data[:, 0], :, data[:, 2]+1, data[:, 1]+0],\n",
    "    representations[data[:, 0], :, data[:, 2]+1, data[:, 1]+1],\n",
    "], dim=0)\n",
    "norms_of_patches = torch.linalg.norm(reprs_of_patches, dim=1)\n",
    "print(f'norms 4x4 patches: min {norms_of_patches.min():.2f}, max {norms_of_patches.max():.2f}, mean {norms_of_patches.mean():.2f}')\n",
    "print(f'norms of all:      min {norms.min():.2f}, max {norms.max():.2f}, mean {norms.mean():.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(reprs_of_patches.mean(dim=0), 'high_norm_anomalies_nyuv2_step50_seed42_reprs_of_patches_mean.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected similarity\n",
    "reprs_of_selected = representations[data[:, 0], :, data[:, 2], data[:, 1]]\n",
    "similarities = torch.cosine_similarity(reprs_of_selected[:, None], reprs_of_selected[None, :], dim=2)\n",
    "print(f'mean similarity of all selected: {similarities.mean():.4f}')\n",
    "\n",
    "\n",
    "# all similarity (random subset of 1000)\n",
    "all_reprs = representations.permute(0, 2, 3, 1).flatten(0,2)[torch.randperm(representations.shape[0])[:1000]]\n",
    "similarities = torch.cosine_similarity(all_reprs[:, None], all_reprs[None, :], dim=2)\n",
    "print(f'mean similarity of random subset of all: {similarities.mean():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50\n",
    "\n",
    "# cosine similarity\n",
    "cosine_similarity = lambda x: torch.cosine_similarity(x[:, None], x[None, :], dim=2)\n",
    "\n",
    "# euclidean distance\n",
    "def euclidean_similarity(x):\n",
    "    distance = ((x[:, None, :] - x[None, :, :])**2).mean(dim=-1)**.5\n",
    "    return 1-distance/distance.max()\n",
    "\n",
    "similarity_measure = cosine_similarity\n",
    "\n",
    "# single tokens\n",
    "for pos_name, (dx, dy) in {'top-left': (0, 0), 'top-right': (0, 1), 'bottom-left': (1, 0), 'bottom-right': (1, 1)}.items():\n",
    "    tmp_reprs = representations[data[:, 0], :, data[:, 2]+dx, data[:, 1]+dy]\n",
    "    tmp_reprs_sorted = tmp_reprs[torch.argsort(norms_of_selected, descending=True)]\n",
    "    similarities_selected = similarity_measure(tmp_reprs_sorted)\n",
    "    mean_similarities_selected = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        top_i = int(len(tmp_reprs_sorted)*(i+1)/n)\n",
    "        # normalize while accounting for self-similarity (1s on diagonal)\n",
    "        mean_similarities_selected[i] = (similarities_selected[:top_i, :top_i].sum() - top_i) / (top_i*(top_i-1))\n",
    "    plt.plot(np.linspace(1, 100, n), mean_similarities_selected, label=pos_name)\n",
    "\n",
    "# patches\n",
    "reprs_of_patches_sorted = reprs_of_patches[torch.argsort(norms_of_patches, descending=True)]\n",
    "similarities_patches = similarity_measure(reprs_of_patches_sorted)\n",
    "mean_similarities_patches = np.zeros(n)\n",
    "for i in range(n):\n",
    "    top_i = int(len(reprs_of_patches)*(i+1)/n)\n",
    "    mean_similarities_patches[i] = (similarities_patches[:top_i, :top_i].sum() - top_i) / (top_i*(top_i-1))\n",
    "plt.plot(np.linspace(1, 100, n), mean_similarities_patches, label=\"patches\")\n",
    "\n",
    "# all (subset)\n",
    "all_reprs_sorted = all_reprs[torch.argsort(all_reprs.norm(dim=1), descending=True)]\n",
    "similarities_all = similarity_measure(all_reprs_sorted)\n",
    "mean_similarities_all = np.zeros(n)\n",
    "for i in range(n):\n",
    "    top_i = int(len(all_reprs)*(i+1)/n)\n",
    "    mean_similarities_all[i] = (similarities_all[:top_i, :top_i].sum() - top_i) / (top_i*(top_i-1))\n",
    "plt.plot(np.linspace(1, 100, n), mean_similarities_all, label=\"all (random subset)\")\n",
    "\n",
    "plt.title(\"Mean similarity of top k% by norm\")\n",
    "plt.xlabel(\"Top k% by norm\")\n",
    "plt.ylabel(\"Mean similarity\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Mean patch similarity: {(similarities_patches.sum() - len(similarities_patches)) / (len(similarities_patches)*(len(similarities_patches)-1)):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity to average repr\n",
    "\n",
    "bins = 100\n",
    "\n",
    "repr_means = {\n",
    "    'patch': reprs_of_patches.mean(dim=0),\n",
    "    'selected': reprs_of_selected.mean(dim=0),\n",
    "}\n",
    "\n",
    "\n",
    "for repr_name, repr_mean in repr_means.items():\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # all (subset)\n",
    "    all_similarities_to_mean = torch.cosine_similarity(repr_mean[None, :], all_reprs, dim=1)\n",
    "    all_hist = torch.histc(all_similarities_to_mean, bins=bins, min=-0.2, max=1.0)\n",
    "    # all_hist /= all_hist.sum() / bins  # normalization to avg bin size = 1\n",
    "    plt.bar(np.linspace(-0.2, 1.0, bins), all_hist.numpy(), width=0.012, label='all (subset)', alpha=0.6, color='blue')\n",
    "\n",
    "    # patches\n",
    "    patch_similarities_to_mean = torch.cosine_similarity(repr_mean[None, :], reprs_of_patches, dim=1)\n",
    "    patch_hist = torch.histc(patch_similarities_to_mean, bins=bins, min=-0.2, max=1.0)\n",
    "    # patch_hist /= patch_hist.sum() / bins  # normalization to avg bin size = 1\n",
    "    plt.bar(np.linspace(-0.2, 1.0, bins), patch_hist.numpy(), width=0.012, label='patches', alpha=0.6, color='purple')\n",
    "\n",
    "    # selected\n",
    "    selected_similarities_to_mean = torch.cosine_similarity(repr_mean[None, :], reprs_of_selected, dim=1)\n",
    "    selected_hist = torch.histc(selected_similarities_to_mean, bins=bins, min=-0.2, max=1.0)\n",
    "    # selected_hist /= selected_hist.sum() / bins  # normalization to avg bin size = 1\n",
    "    plt.bar(np.linspace(-0.2, 1.0, bins), selected_hist.numpy(), width=0.012, label='selected', alpha=0.6, color='orange')\n",
    "\n",
    "    # scatter plots for better visibility\n",
    "    plt.scatter(np.linspace(-0.2, 1.0, bins), all_hist.numpy(), c='blue', s=5)\n",
    "    plt.scatter(np.linspace(-0.2, 1.0, bins), patch_hist.numpy(), c='purple', s=5)\n",
    "    plt.scatter(np.linspace(-0.2, 1.0, bins), selected_hist.numpy(), c='orange', s=5)\n",
    "\n",
    "    plt.title(f\"Cosine Similarity to average anomaly {repr_name} repr\")\n",
    "    plt.xlabel(\"Similarity\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of anomaly norms\n",
    "plt.hist(representations.norm(dim=1).flatten(), bins=80, density=True, label='all', alpha=0.5, range=(0, 1200))\n",
    "plt.hist(norms_of_patches, bins=80, density=True, label='patches', alpha=0.5, range=(0, 1200))\n",
    "plt.hist(norms_of_selected, bins=80, density=True, label='selected', alpha=0.5, range=(0, 1200))\n",
    "plt.title(\"Histogram of anomaly norms\")\n",
    "plt.xlabel(\"Token Norm\")\n",
    "plt.ylabel(\"Probability Density\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(representations[0].norm(dim=0))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap of anomaly positions\n",
    "heatmap = torch.zeros(representations.shape[2:])\n",
    "for d in data:\n",
    "    heatmap[d[2], d[1]] += 1\n",
    "plt.imshow(heatmap, cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title(\"Heatmap of selected anomaly positions\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
