{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Correspondence\n",
    "\n",
    "semantic correspondence with degradations on the target image, like color changes, texture overlay, blurring, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdhelper import SD\n",
    "import torch\n",
    "import numpy as np\n",
    "import datasets\n",
    "from tqdm.autonotebook import tqdm, trange\n",
    "from matplotlib import pyplot as plt\n",
    "import PIL.Image\n",
    "from typing import Callable\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from typing import Any\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_dataset('0jl/SPair-71k', 'data', split='train', trust_remote_code=True)\n",
    "pairs = datasets.load_dataset('0jl/SPair-71k', 'pairs', split='test', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_keys = ['src_bndbox','trg_bndbox','category','viewpoint_variation','scale_variation',]\n",
    "metadata = [{'i': i, 'src_kp': src_kp, 'trg_kp': trg_kp, 'src_size': pair['src_img'].size, 'trg_size': pair['trg_img'].size} | {k: pair[k] for k in metadata_keys} for i, pair in enumerate(tqdm(pairs)) for src_kp, trg_kp in zip(pair['src_kps'], pair['trg_kps'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate semantic correspondence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = SD('SD1.5', disable_progress_bar=True)\n",
    "all_blocks = sd.available_extract_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolation_steps = np.linspace(0, 1, 5)\n",
    "correct = {block: [[] for _ in interpolation_steps] for block in sd.available_extract_positions}\n",
    "positions = {block: [[] for _ in interpolation_steps] for block in sd.available_extract_positions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = sd.available_extract_positions[:6]\n",
    "blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gbr(arr: np.ndarray, interpolation: float):\n",
    "    return arr[:,:,::-1] * interpolation + arr * (1-interpolation)\n",
    "\n",
    "grass_image = np.array(PIL.Image.open('../data/grass.png').convert('RGB'))\n",
    "def add_grass(img: np.ndarray, interpolation: float):\n",
    "    tmp = 1 - interpolation/2\n",
    "    return img * tmp + grass_image[:img.shape[0],:img.shape[1],:] * (1-tmp)\n",
    "\n",
    "def edges_only(arr: np.ndarray, interpolation: float):\n",
    "    gray_tensor = torch.from_numpy(np.dot(arr[...,:3], [0.2989, 0.5870, 0.1140]))[None,None,:,:]  # convert to grayscale\n",
    "    \n",
    "    # Sobel kernels\n",
    "    kx = torch.tensor([[[[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]]], dtype=torch.float64)\n",
    "    ky = torch.tensor([[[[-1, -2, -1], [0, 0, 0], [1, 2, 1]]]], dtype=torch.float64)\n",
    "    \n",
    "    dx = F.conv2d(gray_tensor, kx, padding=1)\n",
    "    dy = F.conv2d(gray_tensor, ky, padding=1)\n",
    "    \n",
    "    edges = torch.sqrt(dx**2 + dy**2)[0,0].numpy()\n",
    "    edges **= .5  # increase sensitivity\n",
    "    edges = (edges / edges.max() * 255).astype(np.uint8)  # normalize\n",
    "    return np.stack([edges] * 3, axis=-1) * interpolation + arr * (1-interpolation)\n",
    "\n",
    "def blur(arr: np.ndarray, interpolation: float):\n",
    "    return np.array(PIL.Image.fromarray(arr).filter(PIL.ImageFilter.GaussianBlur(radius=16 * interpolation)))\n",
    "\n",
    "conversion_function = blur\n",
    "\n",
    "# precalculate representations\n",
    "transform_img = lambda img: img.resize(tuple(np.array(img.size) * 512 // max(img.size)))\n",
    "representations = [[] for _ in interpolation_steps]\n",
    "for x in tqdm(data, desc='Calculating representations'):\n",
    "    prompt = ''# x['name'].split('/')[0]\n",
    "    img = np.array(transform_img(x['img']))\n",
    "    img = [conversion_function(img, i).astype(np.uint8) for i in interpolation_steps]\n",
    "    rs = sd.img2repr(img, blocks, 50, prompt=prompt, seed=42)\n",
    "    rs = [r.apply(lambda x: x / torch.norm(x, dim=0, keepdim=True)) for r in rs]  # normalize\n",
    "    for i, r in enumerate(rs):\n",
    "        representations[i].append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del sd\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate percentage of correct keypoints at 10% of the bounding box (PCK@0.1_bbox)\n",
    "\n",
    "for block in tqdm(blocks, desc='Blocks'):\n",
    "    representations_concat = [[r.at(block).concat().cuda() for r in rs] for rs in representations]\n",
    "    for x in (t:=tqdm(pairs, desc=f'Calculating SC for {block}')):\n",
    "        if x['src_data_index'] >= len(representations_concat[0]): continue\n",
    "        a = representations_concat[0][x['src_data_index']]\n",
    "        tbb_max = max(x['trg_bndbox'][2] - x['trg_bndbox'][0], x['trg_bndbox'][3] - x['trg_bndbox'][1])\n",
    "        sxs = [sx*a.shape[2]//x['src_img'].size[0] for sx, sy in x['src_kps']]\n",
    "        sys = [sy*a.shape[1]//x['src_img'].size[1] for sx, sy in x['src_kps']]\n",
    "        for j, modified_repr in enumerate(representations_concat):\n",
    "            if x['trg_data_index'] >= len(modified_repr): continue\n",
    "            b = modified_repr[x['trg_data_index']]\n",
    "            argmaxes = (b[:,None,:,:] * a[:, sys, sxs, None, None]).sum(0).flatten(1).argmax(1).cpu()\n",
    "            for (argmax,[tx,ty]) in zip(argmaxes, x['trg_kps']):\n",
    "                y_max, x_max = np.unravel_index(argmax, b.shape[1:])\n",
    "                x_max_pixel = x_max * x['trg_img'].size[0] / b.shape[2]\n",
    "                y_max_pixel = y_max * x['trg_img'].size[1] / b.shape[1]\n",
    "                relative_distance = ((x_max_pixel - tx)**2 + (y_max_pixel - ty)**2) ** 0.5 / tbb_max\n",
    "                correct[block][j].append(relative_distance < 0.1)\n",
    "                positions[block][j].append((x_max_pixel, y_max_pixel))\n",
    "\n",
    "    del representations_concat\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for block, values in correct.items():\n",
    "    print(block, np.mean(values, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcks = np.array([np.mean(x, axis=1) for x in correct.values()])\n",
    "np.save(f'sc_pck_blur_on_trg_{sd.model_name}.npy', pcks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(8, 6))\n",
    "colors = plt.cm.rainbow(np.linspace(0, 1, len(all_blocks)))\n",
    "for block_idx, (block, color) in enumerate(zip(all_blocks, colors)):\n",
    "    axs[0].plot(interpolation_steps, pcks[block_idx], label=block, color=color)\n",
    "axs[0].legend(bbox_to_anchor=(1.01, 0.5), loc='center left')\n",
    "axs[0].set_xticklabels([])\n",
    "axs[0].set_ylabel('PCK@$0.1_{bbox}$')\n",
    "\n",
    "colors = plt.cm.rainbow(np.linspace(0, 1, len(all_blocks)))\n",
    "for block_idx, (block, color) in enumerate(zip(all_blocks, colors)):\n",
    "    init_acc = pcks[block_idx, 0]\n",
    "    acc_change = (pcks[block_idx] - init_acc) / init_acc\n",
    "    axs[1].plot(interpolation_steps, acc_change, label=block, color=color)\n",
    "axs[1].set_xlabel('Interpolation step')\n",
    "axs[1].set_ylabel('Rel. Change in PCK@$0.1_{bbox}$')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise semantic correspondence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot PCK over category\n",
    "def plot_pck_over_category(correct, metadata):\n",
    "    categories = list(set(x['category'] for x in metadata))\n",
    "    bins = [[] for _ in categories]\n",
    "    for category, c in zip([x['category'] for x in metadata], correct):\n",
    "        bins[categories.index(category)].append(c)\n",
    "    pcks = [np.mean(b)*100 for b in bins]\n",
    "    plt.bar(range(len(categories)), pcks)\n",
    "    plt.xticks(range(len(categories)), pairs.features['category_id'].names, rotation=90)\n",
    "    for i, pck in enumerate(pcks):\n",
    "        plt.text(i, pck, f'{pck:.2f}', ha='center', va='bottom', fontsize=8)\n",
    "        plt.text(i+0.07, 3, f'{len(bins[i])}', ha='center', va='bottom', rotation=90, color='white', fontsize=8)\n",
    "    plt.xlabel('Category')\n",
    "    plt.ylabel('PCK@$0.1_{bbox}$')\n",
    "    # plt.title('PCK@$0.1_{bbox}$ over category')\n",
    "\n",
    "plt.figure(figsize=(len(interpolation_steps)*4, len(correct)*4))\n",
    "for i, (block, correct_block) in enumerate(correct.items()):\n",
    "    for j, (interpolation_step, correct_interpolation_step) in enumerate(zip(interpolation_steps, correct_block)):\n",
    "        plt.subplot(len(correct), len(interpolation_steps), i*len(interpolation_steps) + j + 1)\n",
    "        plt.title(f'{block} {interpolation_step:.2f}')\n",
    "        plot_pck_over_category(correct_interpolation_step, metadata)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot PCK over viewpoint variation\n",
    "def plot_pck_over_viewpoint_variation(correct, metadata):\n",
    "    bins = [[], [], []]\n",
    "    for viewpoint_variation, c in zip([x['viewpoint_variation'] for x in metadata], correct):\n",
    "        bins[viewpoint_variation].append(c)\n",
    "    pcks = [np.mean(b)*100 for b in bins]\n",
    "    plt.figure()\n",
    "    plt.bar(range(3), pcks)\n",
    "    plt.xticks(range(3), ['low', 'medium', 'high'])\n",
    "    for i, pck in enumerate(pcks):\n",
    "        plt.text(i, pck, f'{pck:.2f}', ha='center', va='bottom')\n",
    "        plt.text(i, 3, f'{len(bins[i])}', ha='center', va='bottom', rotation=90, color='white')\n",
    "    plt.xlabel('Viewpoint variation')\n",
    "    plt.ylabel('PCK@$0.1_{bbox}$')\n",
    "    plt.title('PCK@$0.1_{bbox}$ over viewpoint variation')\n",
    "    plt.show()\n",
    "\n",
    "plot_pck_over_viewpoint_variation(correct, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot PCK over bounding box scale variation\n",
    "def plot_pck_over_scale_variation(correct, metadata):\n",
    "    bins = [[], [], []]\n",
    "    for scale_variation, c in zip([x['scale_variation'] for x in metadata], correct):\n",
    "        bins[scale_variation].append(c)\n",
    "    pcks = [np.mean(b)*100 for b in bins]\n",
    "    plt.figure()\n",
    "    plt.bar(range(3), pcks)\n",
    "    plt.xticks(range(3), ['low', 'medium', 'high'])\n",
    "    for i, pck in enumerate(pcks):\n",
    "        plt.text(i, pck, f'{pck:.2f}', ha='center', va='bottom')\n",
    "        plt.text(i, 3, f'{len(bins[i])}', ha='center', va='bottom', rotation=90, color='white')\n",
    "    plt.xlabel('Scale variation')\n",
    "    plt.ylabel('PCK@$0.1_{bbox}$')\n",
    "    plt.title('PCK@$0.1_{bbox}$ over scale variation')\n",
    "    plt.show()\n",
    "\n",
    "plot_pck_over_scale_variation(correct, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot PCK over src and trg bounding box size\n",
    "def plot_pck_over_bbox_size(correct, metadata):\n",
    "    src_shapes = np.array([x['src_bndbox'] for x in metadata])\n",
    "    src_sizes = (src_shapes[:,2] - src_shapes[:,0]) * (src_shapes[:,3] - src_shapes[:,1])\n",
    "    trg_shapes = np.array([x['trg_bndbox'] for x in metadata])\n",
    "    trg_sizes = (trg_shapes[:,2] - trg_shapes[:,0]) * (trg_shapes[:,3] - trg_shapes[:,1])\n",
    "    for name, sizes in [('src', src_sizes), ('trg', trg_sizes)]:\n",
    "        bins = [[] for _ in range(10)]\n",
    "        min_size = sizes.min() ** .5  # sqrt for more useful bins (relative to side length instead of area)\n",
    "        max_size = sizes.max() ** .5 + 1\n",
    "        for size, c in zip(sizes, correct):\n",
    "            idx = int((size**.5 - min_size) / (max_size - min_size) * 10)\n",
    "            bins[idx].append(c)\n",
    "        pcks = [np.mean(b)*100 for b in bins]\n",
    "        plt.figure()\n",
    "        plt.bar(range(10), pcks)\n",
    "        plt.xticks(range(10), [f'{(min_size + i*(max_size - min_size)/10)**2/1000:.0f}k-{(min_size + (i+1)*(max_size - min_size)/10)**2/1000:.0f}k px' for i in range(10)], rotation=45)\n",
    "        for i, pck in enumerate(pcks):\n",
    "            plt.text(i, pck, f'{pck:.2f}', ha='center', va='bottom')\n",
    "            plt.text(i, 3, f'{len(bins[i])}', ha='center', va='bottom', rotation=90, color='white')\n",
    "        plt.xlabel(f'{name} bounding box size')\n",
    "        plt.ylabel('PCK@$0.1_{bbox}$')\n",
    "        plt.title(f'PCK@$0.1_{{bbox}}$ over {name} bounding box size')\n",
    "        plt.show()\n",
    "\n",
    "plot_pck_over_bbox_size(correct, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot PCK over difference in bounding box sizes\n",
    "def plot_pck_over_bbox_size_diff(correct, metadata):\n",
    "    src_shapes = np.array([x['src_bndbox'] for x in metadata])\n",
    "    src_sizes = (src_shapes[:,2] - src_shapes[:,0]) * (src_shapes[:,3] - src_shapes[:,1])\n",
    "    trg_shapes = np.array([x['trg_bndbox'] for x in metadata])\n",
    "    trg_sizes = (trg_shapes[:,2] - trg_shapes[:,0]) * (trg_shapes[:,3] - trg_shapes[:,1])\n",
    "    diffs = np.abs(src_sizes - trg_sizes)\n",
    "    bins = [[] for _ in range(10)]\n",
    "    min_size = diffs.min() ** .5  # sqrt for more useful bins (relative to side length instead of area)\n",
    "    max_size = diffs.max() ** .5 + 1\n",
    "    for size, c in zip(diffs, correct):\n",
    "        idx = int((size**.5 - min_size) / (max_size - min_size) * 10)\n",
    "        bins[idx].append(c)\n",
    "    pcks = [np.mean(b)*100 for b in bins]\n",
    "    plt.figure()\n",
    "    plt.bar(range(10), pcks)\n",
    "    plt.xticks(range(10), [f'{(min_size + i*(max_size - min_size)/10)**2/1000:.0f}k-{(min_size + (i+1)*(max_size - min_size)/10)**2/1000:.0f}k px' for i in range(10)], rotation=45)\n",
    "    for i, pck in enumerate(pcks):\n",
    "        plt.text(i, pck, f'{pck:.2f}', ha='center', va='bottom')\n",
    "        plt.text(i, 3, f'{len(bins[i])}', ha='center', va='bottom', rotation=90, color='white')\n",
    "    plt.xlabel('Difference in bounding box sizes')\n",
    "    plt.ylabel('PCK@$0.1_{bbox}$')\n",
    "    plt.title('PCK@$0.1_{bbox}$ over difference in bounding box sizes')\n",
    "    plt.show()\n",
    "\n",
    "plot_pck_over_bbox_size_diff(correct, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot PCK over bouding box aspect ratio\n",
    "def plot_pck_over_bbox_aspect_ratio(correct, metadata):\n",
    "    src_shapes = np.array([x['src_bndbox'] for x in metadata])\n",
    "    src_ratios = (src_shapes[:,2] - src_shapes[:,0]) / (src_shapes[:,3] - src_shapes[:,1])\n",
    "    trg_shapes = np.array([x['trg_bndbox'] for x in metadata])\n",
    "    trg_ratios = (trg_shapes[:,2] - trg_shapes[:,0]) / (trg_shapes[:,3] - trg_shapes[:,1])\n",
    "    for name, ratios in [('src', src_ratios), ('trg', trg_ratios)]:\n",
    "        bin_names = ['< 1:4', '1:4 - 1:2', '1:2 - 1:1', '1:1 - 2:1', '2:1 - 4:1', '> 4:1']\n",
    "        bins = [[] for _ in bin_names]\n",
    "        min_ratio = ratios.min()\n",
    "        max_ratio = ratios.max()+1\n",
    "        for ratio, c in zip(ratios, correct):\n",
    "            idx = int(np.log2(ratio) + 2)\n",
    "            if idx < 0: idx = 0\n",
    "            if idx >= len(bins): idx = len(bins)-1\n",
    "            bins[idx].append(c)\n",
    "        pcks = [np.mean(b)*100 for b in bins]\n",
    "        plt.figure()\n",
    "        plt.bar(range(len(bin_names)), pcks)\n",
    "        plt.xticks(range(len(bin_names)), bin_names, rotation=45)\n",
    "        for i, pck in enumerate(pcks):\n",
    "            plt.text(i, pck, f'{pck:.2f}', ha='center', va='bottom')\n",
    "            plt.text(i, 3, f'{len(bins[i])}', ha='center', va='bottom', rotation=90, color='white')\n",
    "        plt.xlabel(f'{name} bounding box aspect ratio')\n",
    "        plt.ylabel('PCK@$0.1_{bbox}$')\n",
    "        plt.title(f'PCK@$0.1_{{bbox}}$ over {name} bounding box aspect ratio')\n",
    "        plt.show()\n",
    "\n",
    "plot_pck_over_bbox_aspect_ratio(correct, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot PCK over src and trg keypoint positions\n",
    "def plot_pck_over_kp_position(correct, metadata, scale_factor=2):\n",
    "    src_kps = np.array([x['src_kp'] for x in metadata])\n",
    "    trg_kps = np.array([x['trg_kp'] for x in metadata])\n",
    "    for name, kps in [('src', src_kps), ('trg', trg_kps)]:\n",
    "        min_x = kps[:,0].min() // scale_factor\n",
    "        max_x = kps[:,0].max() // scale_factor\n",
    "        min_y = kps[:,1].min() // scale_factor\n",
    "        max_y = kps[:,1].max() // scale_factor\n",
    "        matrix = np.zeros((max_y - min_y + 1, max_x - min_x + 1, 2))\n",
    "        for (x, y), c in zip(kps, correct):\n",
    "            matrix[y//scale_factor-min_y, x//scale_factor-min_x, :] += c, 1\n",
    "        pck_matrix = matrix[:,:,0] / matrix[:,:,1]\n",
    "\n",
    "        # plot count\n",
    "        plt.figure()\n",
    "        plt.imshow(matrix[:,:,1], cmap='viridis', interpolation='nearest')\n",
    "        plt.colorbar()\n",
    "        plt.xlabel(f'{name} keypoint x')\n",
    "        plt.ylabel(f'{name} keypoint y')\n",
    "        plt.title(f'Count of keypoints over {name} keypoint position')\n",
    "        plt.show()\n",
    "\n",
    "        # plot pck matrix\n",
    "        plt.figure()\n",
    "        plt.imshow(pck_matrix, cmap='viridis', interpolation='nearest', vmin=0, vmax=1)\n",
    "        plt.colorbar()\n",
    "        plt.xlabel(f'{name} keypoint x')\n",
    "        plt.ylabel(f'{name} keypoint y')\n",
    "        plt.title(f'PCK@$0.1_{{bbox}}$ over {name} keypoint position')\n",
    "        plt.show()\n",
    "\n",
    "plot_pck_over_kp_position(correct, metadata, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot PCK over src and trg keypoint positions\n",
    "# might be useful to see if certain pixels in the regions are ignored\n",
    "def plot_pck_over_kp_position(correct, metadata, size=32):\n",
    "    src_kps = np.array([x['src_kp'] for x in metadata])\n",
    "    trg_kps = np.array([x['trg_kp'] for x in metadata])\n",
    "    for name, kps in [('src', src_kps), ('trg', trg_kps)]:\n",
    "        matrix = np.zeros((size, size, 2))\n",
    "        for (x, y), c in zip(kps, correct):\n",
    "            matrix[y%size, x%size, :] += c, 1\n",
    "        pck_matrix = matrix[:,:,0] / matrix[:,:,1]\n",
    "        plt.figure()\n",
    "        plt.imshow(pck_matrix, cmap='viridis', interpolation='nearest', vmin=0, vmax=1)\n",
    "        plt.colorbar()\n",
    "        plt.xlabel(f'{name} keypoint x (mod {size})')\n",
    "        plt.ylabel(f'{name} keypoint y (mod {size})')\n",
    "        plt.title(f'PCK@$0.1_{{bbox}}$ over {name} keypoint position')\n",
    "        plt.show()\n",
    "\n",
    "plot_pck_over_kp_position(correct, metadata, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_failures(get_distance: Callable[[bool,Any,int,int], int|None], normalize_values: Callable[[int], float], normalize_distance: Callable[[int], float] = lambda x: x):\n",
    "    count_over_dist = defaultdict(int)\n",
    "    for c, m, (x,y) in zip(correct, metadata, positions):\n",
    "        dist = get_distance(c, m, x, y)\n",
    "        if dist is None: continue\n",
    "        count_over_dist[dist] += 1\n",
    "    counts_total = sum(val for key, val in count_over_dist.items())\n",
    "    x = []\n",
    "    y = []\n",
    "    for distance, count in sorted(count_over_dist.items()):\n",
    "        y.append(normalize_values(count) / counts_total)\n",
    "        x.append(normalize_distance(distance+1))\n",
    "    plt.scatter(x, y, s=2, alpha=0.5)\n",
    "    plt.xlabel('Distance to source keypoint (pixels)')\n",
    "    plt.ylabel('Fraction of failed keypoints per pixel')\n",
    "\n",
    "# both\n",
    "plt.xlim(0, 200)\n",
    "plot_failures(lambda c, m, x, y: np.hypot(m['src_kp'][0]-x, m['src_kp'][1]-y)**2//25 if not c else None, lambda x: x/np.pi/25, lambda x: (x*25)**.5)\n",
    "plot_failures(lambda c, m, x, y: np.hypot(m['src_kp'][0]-x, m['src_kp'][1]-y)**2//25, lambda x: x/np.pi/25, lambda x: (x*25)**.5)\n",
    "plt.legend(['Failed KP', 'All KP'])\n",
    "plt.title('Distance of failed keypoint guess to source keypoint')\n",
    "plt.show()\n",
    "\n",
    "# x\n",
    "plt.xlim(0, 200)\n",
    "plot_failures(lambda c, m, x, y: abs(m['src_kp'][0] - x)//1 if not c else None, lambda x: x/2)\n",
    "plot_failures(lambda c, m, x, y: abs(m['src_kp'][0] - x)//1, lambda x: x/2)\n",
    "plt.legend(['Failed KP', 'All KP'])\n",
    "plt.title('X-Distance of failed keypoint guess to source keypoint')\n",
    "plt.show()\n",
    "\n",
    "# y\n",
    "plt.xlim(0, 200)\n",
    "plot_failures(lambda c, m, x, y: abs(m['src_kp'][1] - y)//1 if not c else None, lambda x: x/2)\n",
    "plot_failures(lambda c, m, x, y: abs(m['src_kp'][1] - y)//1, lambda x: x/2)\n",
    "plt.legend(['Failed KP', 'All KP'])\n",
    "plt.title('Y-Distance of failed keypoint guess to source keypoint')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCK over keypoint distance\n",
    "n = 50\n",
    "distances = {i: [] for i in range(n)}\n",
    "counts = {i: 0 for i in range(n)}\n",
    "for c, m, (x,y) in zip(correct, metadata, positions):\n",
    "    max_size = max(max(m['src_size']), max(m['trg_size']))\n",
    "    distance = np.hypot((m['src_kp'][0] - m['trg_kp'][0]) / max_size, (m['src_kp'][1] - m['trg_kp'][1]) / max_size)\n",
    "    key = int(distance*n)\n",
    "    if key > n-1:\n",
    "        key = n-1\n",
    "    distances[key].append(c)\n",
    "    counts[key] += 1\n",
    "\n",
    "plt.bar(counts.keys(), counts.values(), color='lightblue')\n",
    "plt.ylabel('Number of keypoints', color='lightblue')\n",
    "plt.xlabel('Distance between keypoints (normalized)')\n",
    "plt.xticks(range(0,n,n//10), [f'{i/n:.1f}' for i in range(0,n,n//10)])\n",
    "plt.twinx()\n",
    "plt.plot(distances.keys(), [np.mean(d)*100 for d in distances.values()], 'red')\n",
    "plt.ylabel('PCK@$0.1_{bbox}$ (%)', color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize random failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize random failures\n",
    "i = random.randint(0, len(metadata))\n",
    "while correct[i]:\n",
    "    i = random.randint(0, len(metadata))\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(pairs[metadata[i]['i']]['src_img'])\n",
    "plt.scatter(metadata[i]['src_kp'][0], metadata[i]['src_kp'][1], c='g', marker='x', s=200)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(pairs[metadata[i]['i']]['trg_img'])\n",
    "plt.scatter(metadata[i]['trg_kp'][0], metadata[i]['trg_kp'][1], c='g', marker='x', s=200)\n",
    "plt.scatter(positions[i][0], positions[i][1], c='r', marker='x', s=200)\n",
    "relative_distance = ((positions[i][0] - metadata[i]['trg_kp'][0])**2 + (positions[i][1] - metadata[i]['trg_kp'][1])**2) ** 0.5 / max(metadata[i]['trg_bndbox'][2] - metadata[i]['trg_bndbox'][0], metadata[i]['trg_bndbox'][3] - metadata[i]['trg_bndbox'][1])\n",
    "plt.title(f'PCK@0.1_bbox: {relative_distance:.2f}')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
