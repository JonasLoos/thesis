{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representation Classifier\n",
    "\n",
    "dataset: `imagenet-1k`\n",
    "\n",
    "models based on AvgPool2d + Linear:\n",
    "* conv_in: 321k params\n",
    "* down_blocks[0]: 321k params\n",
    "* down_blocks[1]: 641k params\n",
    "* down_blocks[2]: 1281k params\n",
    "* down_blocks[3]: 1281k params\n",
    "* mid_block: 1281k params\n",
    "* up_blocks[0]: 1281k params\n",
    "* up_blocks[1]: 1281k params\n",
    "* up_blocks[2]: 641k params\n",
    "* up_blocks[3]: 321k params\n",
    "* conv_out: 5k params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from trainplot import plot, TrainPlot\n",
    "from trainplot.trainplot import TrainPlotPlotlyExperimental\n",
    "from collections import defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = load_from_disk(\"...\").with_format(\"torch\").select(range(10_000)).train_test_split(test_size=0.1, seed=42)\n",
    "train_loader = DataLoader(dataset['train'], batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset['test'], batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, channel_size=1280, spatial_size=8, num_classes=1000):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(channel_size, num_classes)\n",
    "        self.pool = nn.AvgPool2d(spatial_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(self.pool(x), start_dim=1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SimpleCNNClassifier(nn.Module):\n",
    "    def __init__(self, channel_size=1280, spatial_size=8, num_classes=1000):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(channel_size, num_classes, kernel_size=1, padding=0)\n",
    "        self.pool = nn.MaxPool2d(spatial_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = torch.flatten(self.pool(x), start_dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "models = {\n",
    "    name: SimpleClassifier(channel_size=value.shape[1], spatial_size=value.shape[-1]).cuda()\n",
    "    for name, value in next(iter(train_loader)).items()\n",
    "    if name != 'label'\n",
    "}\n",
    "print(f'Created {len(models)} models:')\n",
    "for name, model in models.items():\n",
    "    print(f'  {name}: {sum(p.numel() for p in model.parameters() if p.requires_grad)//1000}k params')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizers = {name: optim.Adam(model.parameters(), lr=0.001) for name, model in models.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_train = TrainPlotPlotlyExperimental()\n",
    "tp_test = TrainPlotPlotlyExperimental()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_progress = tqdm(range(20), desc=\"Epoch\")\n",
    "step_progress = tqdm(total=len(train_loader), desc=\"Step\")\n",
    "model_progress = tqdm(models.keys(), desc=\"Model\")\n",
    "total_train_step = 0\n",
    "accuracies_ema = defaultdict(float)\n",
    "for epoch in epoch_progress:\n",
    "    # train\n",
    "    step_progress.total = len(train_loader)\n",
    "    step_progress.desc = \"Train\"\n",
    "    for model in models.values():\n",
    "        model.train()\n",
    "    accuracies = defaultdict(list)\n",
    "    step_progress.reset()\n",
    "    for batch in train_loader:\n",
    "        model_progress.reset()\n",
    "        for name in models:\n",
    "            model_progress.set_postfix_str(name)\n",
    "            optimizers[name].zero_grad()\n",
    "            x = batch[name].cuda()\n",
    "            y = batch[\"label\"].cuda()\n",
    "            y_pred = models[name](x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            accuracy = (y_pred.argmax(dim=1) == y).float().mean().cpu().item()\n",
    "            accuracies[name] += accuracy,\n",
    "            accuracies_ema[name] = 0.8 * accuracies_ema[name] + 0.2 * accuracy\n",
    "            loss.backward()\n",
    "            optimizers[name].step()\n",
    "            model_progress.update()\n",
    "        tp_train(step=total_train_step, **accuracies_ema)\n",
    "        total_train_step += 1\n",
    "        step_progress.update()\n",
    "    # accuracies = {name: accuracy/len(train_loader) for name, accuracy in accuracies.items()}\n",
    "    # tp_train(**accuracies)\n",
    "\n",
    "    # test\n",
    "    test_accuracies = defaultdict(float)\n",
    "    for model in models.values():\n",
    "        model.eval()\n",
    "    step_progress.reset()\n",
    "    step_progress.total = len(test_loader)\n",
    "    step_progress.desc = \"Test\"\n",
    "    for batch in test_loader:\n",
    "        model_progress.reset()\n",
    "        for name in models:\n",
    "            model_progress.set_postfix_str(name)\n",
    "            x = batch[name].cuda()\n",
    "            y = batch[\"label\"].cuda()\n",
    "            y_pred = models[name](x)\n",
    "            test_accuracies[name] += (y_pred.argmax(dim=1) == y).float().mean().cpu().item()\n",
    "            model_progress.update()\n",
    "        step_progress.update()\n",
    "    test_accuracy = {name: accuracy/len(test_loader) for name, accuracy in test_accuracies.items()}\n",
    "    tp_test(**test_accuracy)\n",
    "    # print(f\"Epoch {epoch}: accuracy {accuracy.item():.2%}, test accuracy {test_accuracy.item():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, model in models.items():\n",
    "#     torch.save(model.state_dict(), f\"../classifier-models/{name}-10k-20ep.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plot barplot of test accuracies for each model\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(test_accuracy.keys(), test_accuracy.values())\n",
    "plt.title(\"Test accuracy after 20 epochs\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
