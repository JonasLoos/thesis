{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Correspondence with position subtraction\n",
    "\n",
    "train a position estimator and then optimize the extracted SD representations such that the position isn't represented anymore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdhelper import SD\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import datasets\n",
    "from tqdm.autonotebook import tqdm, trange\n",
    "from matplotlib import pyplot as plt\n",
    "import PIL.Image\n",
    "from typing import Callable\n",
    "import random\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = SD('SD15')\n",
    "data = datasets.load_dataset('0jl/SPair-71k', 'data', split='train', trust_remote_code=True)\n",
    "pairs = datasets.load_dataset('0jl/SPair-71k', 'pairs', split='test', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_keys = ['src_bndbox','trg_bndbox','category','viewpoint_variation','scale_variation',]\n",
    "metadata = [{'i': i, 'src_kp': src_kp, 'trg_kp': trg_kp, 'src_size': pair['src_img'].size, 'trg_size': pair['trg_img'].size} | {k: pair[k] for k in metadata_keys} for i, pair in enumerate(tqdm(pairs)) for src_kp, trg_kp in zip(pair['src_kps'], pair['trg_kps'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate semantic correspondence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 'up_blocks[1]'\n",
    "img_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precalculate representations\n",
    "\n",
    "def expand_and_resize(x: PIL.Image.Image, size, border_pad=True):\n",
    "    n, m = x.size\n",
    "    s = max(n, m)\n",
    "    r = PIL.Image.new('RGB', (s, s))\n",
    "    r.paste(x, ((s-n)//2, (s-m)//2))\n",
    "    if border_pad:\n",
    "        # pad with border\n",
    "        if n > m:\n",
    "            r.paste(x.crop((0, 0, n, 1)).resize((n,(s-m)//2)), (0, 0))\n",
    "            r.paste(x.crop((0, m-1, n, m)).resize((n,(s-m)//2)), (0, m+(s-m)//2))\n",
    "        elif m > n:\n",
    "            r.paste(x.crop((0, 0, 1, m)).resize(((s-n)//2,m)), (0, 0))\n",
    "            r.paste(x.crop((n-1, 0, n, m)).resize(((s-n)//2,m)), (n+(s-n)//2, 0))\n",
    "    return r.resize((size, size))\n",
    "\n",
    "transform_img = lambda img: expand_and_resize(img, img_size, True)\n",
    "\n",
    "representations = []\n",
    "for x in tqdm(data, desc='Calculating representations'):\n",
    "    r = sd.img2repr(transform_img(x['img']), [p], 100, prompt=x['name'].split('/')[0])\n",
    "    r = r.apply(lambda x: x / torch.norm(x, dim=0, keepdim=True))  # normalize\n",
    "    representations.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, num_channels, H, W = representations[0][p].shape\n",
    "assert H == W\n",
    "\n",
    "class PositionClassifier(nn.Module):\n",
    "    def __init__(self, num_channels: int, size: int):\n",
    "        super().__init__()\n",
    "        self.layer_x = nn.Linear(num_channels, size)\n",
    "        self.layer_y = nn.Linear(num_channels, size)\n",
    "\n",
    "    def forward(self, repr):\n",
    "        x = self.layer_x(repr)\n",
    "        y = self.layer_y(repr)\n",
    "        return x, y\n",
    "    \n",
    "device = 'cuda'\n",
    "model = PositionClassifier(num_channels, H).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training progress\n",
    "from trainplot.trainplot import TrainPlotPlotlyExperimental as TrainPlot\n",
    "tp = TrainPlot(threaded=True)\n",
    "# tp.fig.update_yaxes(type=\"log\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train position classifier\n",
    "batch_size = 32\n",
    "model.train()\n",
    "for epoch in trange(20):\n",
    "    indices = np.random.permutation(len(representations))\n",
    "    for i in range(0, len(representations), batch_size):\n",
    "        batch = [representations[p] for p in indices[i:i+batch_size]]\n",
    "        input = torch.stack([x[p].squeeze(0).flatten(1,2).T for x in batch]).to(device=device, dtype=torch.float32)\n",
    "        # current shape of x: [batch_size, num_channels, H, W]\n",
    "        y_x = torch.arange(W, device=device).repeat(H).expand(len(batch), -1).flatten()\n",
    "        y_y = torch.arange(H, device=device).repeat_interleave(W).expand(len(batch), -1).flatten()\n",
    "        pred_x, pred_y = model(input)\n",
    "        loss = F.cross_entropy(pred_x.flatten(0,1), y_x) + F.cross_entropy(pred_y.flatten(0,1), y_y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            tp(\n",
    "                accuracy_x = (pred_x.argmax(dim=2).flatten() == y_x).float().mean().cpu().item(),\n",
    "                accuracy_y = (pred_y.argmax(dim=2).flatten() == y_y).float().mean().cpu().item(),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove positional information from representations\n",
    "# using dynamic learning rate, which increases if convergence is slow\n",
    "representations_unpositioned = []\n",
    "model.eval()\n",
    "for r in tqdm(representations):\n",
    "    r = r[p].squeeze(0).flatten(1,2).T.unsqueeze(0).to(device=device, dtype=torch.float32)\n",
    "    loss, prev_loss = 1, 1\n",
    "    lr = 1.\n",
    "    for i in range(50):\n",
    "        r = r.detach().requires_grad_()\n",
    "        x, y = model(r)\n",
    "        position_loss = F.mse_loss(F.softmax(x, dim=-1), torch.full_like(x, 1/W)) + F.mse_loss(F.softmax(y, dim=-1), torch.full_like(y, 1/H))\n",
    "        nochange_loss = F.mse_loss(r, torch.zeros_like(r))\n",
    "        loss = position_loss + 0.0 * nochange_loss\n",
    "        if prev_loss / loss < 1.05:  # if loss decreases slowly, increase lr\n",
    "            lr *= 2\n",
    "        if prev_loss < loss:  # if loss increases, reset lr\n",
    "            lr = 1.\n",
    "        prev_loss = loss\n",
    "        loss.backward()\n",
    "        r = r - lr * r.grad\n",
    "        # print(loss.item(), lr)\n",
    "    r = r.detach().to(device='cpu', dtype=torch.float16).squeeze(0).T.reshape(num_channels, H, W)\n",
    "    representations_unpositioned.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renormalize representations_unpositioned\n",
    "representations_unpositioned = torch.stack(representations_unpositioned)\n",
    "representations_unpositioned = representations_unpositioned / representations_unpositioned.pow(2).sum(dim=1, keepdim=True).sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate percentage of correct keypoints at 10% of the bounding box (PCK@0.1_bbox)\n",
    "correct = []\n",
    "positions = []\n",
    "for x in (t:=tqdm(pairs, desc='Calculating SC')):\n",
    "    a = representations_unpositioned[x['src_data_index']]\n",
    "    b = representations_unpositioned[x['trg_data_index']]\n",
    "    tbb_max = max(x['trg_bndbox'][2] - x['trg_bndbox'][0], x['trg_bndbox'][3] - x['trg_bndbox'][1])\n",
    "    for ([sx, sy],[tx,ty]) in zip(x['src_kps'], x['trg_kps']):\n",
    "        src_repr = a[:, \n",
    "            int((sy + (max(x['src_img'].size) - x['src_img'].size[1])/2) * a.shape[1] / max(x['src_img'].size)),\n",
    "            int((sx + (max(x['src_img'].size) - x['src_img'].size[0])/2) * a.shape[2] / max(x['src_img'].size)),\n",
    "        ]\n",
    "        cossim = (b * src_repr[:,None,None]).sum(dim=0)\n",
    "        y_max, x_max = np.unravel_index(cossim.argmax().cpu(), cossim.shape)\n",
    "        x_max_pixel = x_max / b.shape[2] * max(x['trg_img'].size) - (max(x['trg_img'].size) - x['trg_img'].size[0]) / 2\n",
    "        y_max_pixel = y_max / b.shape[1] * max(x['trg_img'].size) - (max(x['trg_img'].size) - x['trg_img'].size[1]) / 2\n",
    "        relative_distance = ((x_max_pixel - tx)**2 + (y_max_pixel - ty)**2) ** 0.5 / tbb_max\n",
    "        correct.append(relative_distance < 0.1)\n",
    "        positions.append((x_max_pixel, y_max_pixel))\n",
    "    if len(correct) % 100 == 0:\n",
    "        t.set_postfix(pck=np.mean(correct)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(correct)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference\n",
    "\n",
    "# calculate percentage of correct keypoints at 10% of the bounding box (PCK@0.1_bbox)\n",
    "correct_reference = []\n",
    "positions_reference = []\n",
    "for x in (t:=tqdm(pairs, desc='Calculating SC')):\n",
    "    a = representations[x['src_data_index']].concat()\n",
    "    b = representations[x['trg_data_index']].concat()\n",
    "    tbb_max = max(x['trg_bndbox'][2] - x['trg_bndbox'][0], x['trg_bndbox'][3] - x['trg_bndbox'][1])\n",
    "    for ([sx, sy],[tx,ty]) in zip(x['src_kps'], x['trg_kps']):\n",
    "        src_repr = a[:, \n",
    "            int((sy + (max(x['src_img'].size) - x['src_img'].size[1])/2) * a.shape[1] / max(x['src_img'].size)),\n",
    "            int((sx + (max(x['src_img'].size) - x['src_img'].size[0])/2) * a.shape[2] / max(x['src_img'].size)),\n",
    "        ]\n",
    "        cossim = (b * src_repr[:,None,None]).sum(dim=0)\n",
    "        y_max, x_max = np.unravel_index(cossim.argmax().cpu(), cossim.shape)\n",
    "        x_max_pixel = x_max / b.shape[2] * max(x['trg_img'].size) - (max(x['trg_img'].size) - x['trg_img'].size[0]) / 2\n",
    "        y_max_pixel = y_max / b.shape[1] * max(x['trg_img'].size) - (max(x['trg_img'].size) - x['trg_img'].size[1]) / 2\n",
    "        relative_distance = ((x_max_pixel - tx)**2 + (y_max_pixel - ty)**2) ** 0.5 / tbb_max\n",
    "        correct_reference.append(relative_distance < 0.1)\n",
    "        positions_reference.append((x_max_pixel, y_max_pixel))\n",
    "    if len(correct_reference) % 100 == 0:\n",
    "        t.set_postfix(pck=np.mean(correct_reference)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(correct_reference)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_failures(f: Callable[['Any'], tuple[int,int]], only_fails=False):\n",
    "    fail_distances = defaultdict(int)\n",
    "    for c, tmp, (x,y) in zip(correct, metadata, positions):\n",
    "        if only_fails and c:\n",
    "            continue\n",
    "        x0, y0 = f(tmp)\n",
    "        dist = np.hypot(x0-x, y0-y)\n",
    "        fail_distances[dist**2//25] += 1\n",
    "    fail_distances = sorted(fail_distances.items())\n",
    "    num_fails = sum(val for key, val in fail_distances)\n",
    "    x = []\n",
    "    y = []\n",
    "    for tmp, count in fail_distances:\n",
    "        # if ((tmp+1)*25)**.5 < 20:\n",
    "        #     print(f'until {((tmp+1)*25)**.5:2.0f} pixels: {count} keypoints')\n",
    "        x.append(((tmp+1)*25)**.5)\n",
    "        y.append(count/np.pi/25 / num_fails)\n",
    "    plt.scatter(x, y, s=2, alpha=0.5)\n",
    "    plt.xlabel('Distance to source keypoint (pixels)')\n",
    "    plt.ylabel('Normalized number of failed keypoints per pixel')\n",
    "\n",
    "plt.xlim(0, 200)\n",
    "plot_failures(lambda x: (x['src_kp'][0], x['src_kp'][1]), only_fails=True)\n",
    "plot_failures(lambda x: (x['src_kp'][0], x['src_kp'][1]))\n",
    "# plot_failures(lambda x: (random.randint(100,400), random.randint(100,300)))\n",
    "plt.legend(['Failed KP', 'All KP'])\n",
    "plt.title('Distance of failed keypoint guess to source keypoint')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# failure distance\n",
    "def plot_failures(f: Callable[['Any'], tuple[int,int]], only_fails=False):\n",
    "    fail_distances = defaultdict(int)\n",
    "    for c, tmp, (x,y) in zip(correct, metadata, positions):\n",
    "        if only_fails and c:\n",
    "            continue\n",
    "        fail_distances[f(tmp, x, y)//1] += 1\n",
    "    num_fails = sum(val for key, val in fail_distances.items())\n",
    "    x = []\n",
    "    y = []\n",
    "    for tmp, count in sorted(fail_distances.items()):\n",
    "        x.append((tmp+1))\n",
    "        y.append(count/2 / num_fails)\n",
    "    plt.scatter(x, np.array(y), s=3, alpha=0.5)\n",
    "    plt.xlabel('Distance to source keypoint (pixels)')\n",
    "    plt.ylabel('Normalized number of failed keypoints per row/column')\n",
    "\n",
    "# x\n",
    "plt.xlim(0, 200)\n",
    "plot_failures(lambda tmp, x, y: abs(tmp['src_kp'][0] - x), only_fails=True)\n",
    "plot_failures(lambda tmp, x, y: abs(tmp['src_kp'][0] - x))\n",
    "plt.legend(['Failed KP', 'All KP'])\n",
    "plt.title('X-Distance of failed keypoint guess to source keypoint')\n",
    "plt.show()\n",
    "\n",
    "# y\n",
    "plt.xlim(0, 200)\n",
    "plot_failures(lambda tmp, x, y: abs(tmp['src_kp'][1] - y), only_fails=True)\n",
    "plot_failures(lambda tmp, x, y: abs(tmp['src_kp'][1] - y))\n",
    "plt.legend(['Failed KP', 'All KP'])\n",
    "plt.title('Y-Distance of failed keypoint guess to source keypoint')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCK over keypoint distance\n",
    "n = 50\n",
    "distances = {i: [] for i in range(n)}\n",
    "counts = {i: 0 for i in range(n)}\n",
    "for c, m, (x,y) in zip(correct, metadata, positions):\n",
    "    max_size = max(max(m['src_size']), max(m['trg_size']))\n",
    "    dist = np.hypot((m['src_kp'][0] - m['trg_kp'][0]) / max_size, (m['src_kp'][1] - m['trg_kp'][1]) / max_size)\n",
    "    key = int(dist*n)\n",
    "    if key > n-1:\n",
    "        key = n-1\n",
    "    distances[key].append(c)\n",
    "    counts[key] += 1\n",
    "\n",
    "plt.bar(counts.keys(), counts.values(), color='lightblue')\n",
    "plt.ylabel('Number of keypoints', color='lightblue')\n",
    "plt.xlabel('Distance between keypoints (normalized)')\n",
    "plt.xticks(range(0,n,n//10), [f'{i/n:.1f}' for i in range(0,n,n//10)])\n",
    "plt.twinx()\n",
    "plt.plot(distances.keys(), [np.mean(d)*100 for d in distances.values()], 'red')\n",
    "plt.ylabel('PCK@$0.1_{bbox}$ (%)', color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize random failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize random failures\n",
    "i = random.randint(0, len(metadata))\n",
    "while correct[i]:\n",
    "    i = random.randint(0, len(metadata))\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(pairs[metadata[i]['i']]['src_img'])\n",
    "plt.scatter(metadata[i]['src_kp'][0], metadata[i]['src_kp'][1], c='g', marker='x', s=200)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(pairs[metadata[i]['i']]['trg_img'])\n",
    "plt.scatter(metadata[i]['trg_kp'][0], metadata[i]['trg_kp'][1], c='g', marker='x', s=200)\n",
    "plt.scatter(positions[i][0], positions[i][1], c='r', marker='x', s=200)\n",
    "relative_distance = ((positions[i][0] - metadata[i]['trg_kp'][0])**2 + (positions[i][1] - metadata[i]['trg_kp'][1])**2) ** 0.5 / max(metadata[i]['trg_bndbox'][2] - metadata[i]['trg_bndbox'][0], metadata[i]['trg_bndbox'][3] - metadata[i]['trg_bndbox'][1])\n",
    "plt.title(f'PCK@0.1_bbox: {relative_distance:.2f}')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
