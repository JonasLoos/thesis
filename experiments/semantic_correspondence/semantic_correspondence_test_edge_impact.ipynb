{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdhelper import SD\n",
    "import torch\n",
    "import numpy as np\n",
    "import datasets\n",
    "from tqdm.autonotebook import tqdm, trange\n",
    "from matplotlib import pyplot as plt\n",
    "import PIL.Image\n",
    "from trainplot.trainplot import TrainPlotPlotlyExperimental as TrainPlot\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from typing import Literal, Callable, TypeAlias\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "sd = SD('sd2.1')\n",
    "\n",
    "print(f'Using {sd.model_name} model, available extract positions: {sd.available_extract_positions}')\n",
    "dataset_pairs: datasets.Dataset = datasets.load_dataset('0jl/SPair-71k', trust_remote_code=True, split='test')\n",
    "repr_dataset_name = f'{sd.model_name}-SPair-71k-repr'\n",
    "\n",
    "def expand_and_resize(x: PIL.Image.Image, size = 960, border_pad=True):\n",
    "    n, m = x.size\n",
    "    s = max(n, m)\n",
    "    r = PIL.Image.new('RGB', (s, s))\n",
    "    r.paste(x, ((s-n)//2, (s-m)//2))\n",
    "    if border_pad:\n",
    "        # pad with border\n",
    "        if n > m:\n",
    "            r.paste(x.crop((0, 0, n, 1)).resize((n,(s-m)//2)), (0, 0))\n",
    "            r.paste(x.crop((0, m-1, n, m)).resize((n,(s-m)//2)), (0, m+(s-m)//2))\n",
    "        elif m > n:\n",
    "            r.paste(x.crop((0, 0, 1, m)).resize(((s-n)//2,m)), (0, 0))\n",
    "            r.paste(x.crop((n-1, 0, n, m)).resize(((s-n)//2,m)), (n+(s-n)//2, 0))\n",
    "    return r.resize((size, size))\n",
    "\n",
    "def expand_and_resize_keypoint(x, y, n, m, o, p):\n",
    "    s = max(n, m)\n",
    "    return (x + (s-n)//2) * o / s, (y + (s-m)//2) * p / s\n",
    "\n",
    "def expand_resize_and_pad(x: PIL.Image.Image, size = 960, pad_size = 16):\n",
    "    n, m = x.size\n",
    "    o = max(n, m)\n",
    "    s = size + 2 * pad_size\n",
    "    r = PIL.Image.new('RGB', (s, s))\n",
    "    r.paste(x.resize((int(size*n/o), int(size*m/o))), (pad_size+int(size*(1-n/o)/2), pad_size+int(size*(1-m/o)/2)))\n",
    "    # corners\n",
    "    cx = pad_size + int(size*(1-n/o)/2)\n",
    "    cy = pad_size + int(size*(1-m/o)/2)\n",
    "    r.paste(x.crop((0, 0, 1, 1)).resize((cx, cy)), (0, 0))\n",
    "    r.paste(x.crop((0, m-1, 1, m)).resize((cx, s-cy)), (0, s-cy))\n",
    "    r.paste(x.crop((n-1, 0, n, 1)).resize((s-cx, cy)), (s-cx, 0))\n",
    "    r.paste(x.crop((n-1, m-1, n, m)).resize((s-cx, s-cy)), (s-cx, s-cy))\n",
    "    # edges\n",
    "    r.paste(x.crop((0, 0, 1, m)).resize((cx, s-2*cy)), (0, cy))\n",
    "    r.paste(x.crop((n-1, 0, n, m)).resize((s-cx, s-2*cy)), (s-cx, cy))\n",
    "    r.paste(x.crop((0, 0, n, 1)).resize((s-2*cx, cy)), (cx, 0))\n",
    "    r.paste(x.crop((0, m-1, n, m)).resize((s-2*cx, s-cy)), (cx, s-cy))\n",
    "    return r\n",
    "\n",
    "def expand_resize_and_pad_keypoint(x, y, n, m, o, p, pad_size = 16):\n",
    "    s = max(n, m)\n",
    "    o -= 2 * pad_size\n",
    "    p -= 2 * pad_size\n",
    "    return (x + (s-n)//2) * o / s + pad_size, (y + (s-m)//2) * p / s + pad_size\n",
    "\n",
    "def expand(x: PIL.Image.Image, size = 960):\n",
    "    factor = size / min(x.size)\n",
    "    return x.resize((int(x.size[0]*factor), int(x.size[1]*factor)))\n",
    "\n",
    "def expand_keypoint(x, y, n, m, o, p):\n",
    "    return x * o / n, y * p / m\n",
    "\n",
    "transform_type: TypeAlias = Literal['expand_resize_and_pad', 'expand_and_resize', 'expand', None]\n",
    "\n",
    "def get_transforms(name: transform_type, size=960):\n",
    "    match name:\n",
    "        case 'expand_resize_and_pad':\n",
    "            return partial(expand_resize_and_pad, size=size), expand_resize_and_pad_keypoint\n",
    "        case 'expand_and_resize':\n",
    "            return partial(expand_and_resize, size=size), expand_and_resize_keypoint\n",
    "        case 'expand':\n",
    "            return partial(expand, size=size), expand_keypoint\n",
    "        case None:\n",
    "            return lambda x, *args, **kwargs: x, lambda x, y, n, m, o, p: (x, y)\n",
    "        case _:\n",
    "            raise ValueError(f'Unknown transform name: {name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "def concat_reprs(reprs: dict[str, torch.Tensor], pos: list[str]):\n",
    "    '''Concatenate representations with different spatial sizes into a single tensor with the largest spatial size.'''\n",
    "    # If the representation sizes are not multiples of each other, the bottom and right edges of the spatially larger representations will be 0-padded.\n",
    "    max_spatial = np.array(max(reprs[x].shape[-2:] for x in pos))\n",
    "    min_spatial = np.array(min(reprs[x].shape[-2:] for x in pos))\n",
    "    while (max_spatial > min_spatial).any(): min_spatial *= 2\n",
    "    spatial = min_spatial\n",
    "    num_features1 = sum(reprs[x].shape[1] for x in pos)\n",
    "    repr_full = torch.zeros((num_features1, *spatial), device=sd.device)\n",
    "    i = 0\n",
    "    for p in pos:\n",
    "        r1 = reprs[p]\n",
    "        _, num_channels1, n1, m1 = r1.shape\n",
    "        tmp1 = r1.repeat_interleave(spatial[0]//n1, dim=-2).repeat_interleave(spatial[1]//m1, dim=-1)\n",
    "        repr_full[i:i+num_channels1, :tmp1.shape[-2], :tmp1.shape[-1]] = tmp1.to(repr_full.device)\n",
    "        i += num_channels1\n",
    "    return repr_full\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def sc(\n",
    "        sample: dict,\n",
    "        plot: bool = True,\n",
    "        precomputed_reprs: list | None = None,\n",
    "        extraction_step: int = 1,\n",
    "        pos: list[str] = ['up_blocks[1]'],\n",
    "        transform: Callable = lambda x: x,\n",
    "        transform_keypoint: Callable = lambda x, y, *_: (x, y)):\n",
    "    # load representations\n",
    "    if precomputed_reprs is not None:\n",
    "        repr1 = precomputed_reprs[sample['src_data_index']]\n",
    "        repr2 = precomputed_reprs[sample['trg_data_index']]\n",
    "        assert set(repr1.keys()) == set(repr2.keys())\n",
    "        pos = list(repr1.keys())\n",
    "    else:\n",
    "        category = dataset_pairs.features['category'].names[sample['category']]\n",
    "        repr1 = sd.img2repr(transform(sample['src_img']), extract_positions=pos, step=extraction_step, prompt=category)\n",
    "        repr2 = sd.img2repr(transform(sample['trg_img']), extract_positions=pos, step=extraction_step, prompt=category)\n",
    "    assert isinstance(repr1, dict) and isinstance(repr2, dict)\n",
    "\n",
    "    # concatenate representations\n",
    "    repr1_full = concat_reprs(repr1, pos)\n",
    "    repr2_full = concat_reprs(repr2, pos)\n",
    "\n",
    "    # get images\n",
    "    src_img = transform(sample['src_img'])\n",
    "    trg_img = transform(sample['trg_img'])\n",
    "    sn, sm = src_img.size\n",
    "    tn, tm = trg_img.size\n",
    "    assert len(sample['src_kps']) == len(sample['trg_kps'])\n",
    "\n",
    "    # get bounding box\n",
    "    sbb = np.array(sample['src_bndbox'])\n",
    "    sbb[:2] = transform_keypoint(*sbb[:2], *sample['src_img'].size, sn, sm)\n",
    "    sbb[2:] = transform_keypoint(*sbb[2:], *sample['src_img'].size, sn, sm)\n",
    "    tbb = np.array(sample['trg_bndbox'])\n",
    "    tbb[:2] = transform_keypoint(*tbb[:2], *sample['trg_img'].size, tn, tm)\n",
    "    tbb[2:] = transform_keypoint(*tbb[2:], *sample['trg_img'].size, tn, tm)\n",
    "    tbb_max = max(tbb[2] - tbb[0], tbb[3] - tbb[1])\n",
    "\n",
    "    # solve semantic correspondence for each keypoint pair\n",
    "    pcks = []\n",
    "    for ([sx, sy],[tx,ty]) in zip(sample['src_kps'], sample['trg_kps']):\n",
    "\n",
    "        # transform keypoints and bb\n",
    "        sx, sy = transform_keypoint(sx, sy, *sample['src_img'].size, sn, sm)\n",
    "        tx, ty = transform_keypoint(tx, ty, *sample['trg_img'].size, tn, tm)\n",
    "\n",
    "        # calc similarities\n",
    "        max_spatial1 = np.array(max(repr1[x].shape[-2:] for x in pos))\n",
    "        point = repr1_full[:, int(sy/(sm/max_spatial1[-2])), int(sx/(sn/max_spatial1[-1])), None, None]\n",
    "        similarities = torch.nn.functional.cosine_similarity(repr2_full, point, dim=0).cpu()  # cossim\n",
    "\n",
    "        # similarities = (repr2_full - point).abs().mean(dim=0).cpu()  # MAE - doesn't seem to work well\n",
    "        max_i = similarities.argmax().item()\n",
    "        x_max = max_i % repr2_full.shape[-1]\n",
    "        y_max = max_i // repr2_full.shape[-1]\n",
    "\n",
    "        # calculate error distance -> PCK\n",
    "        x_max_pixel = (x_max+.5) * tn / repr2_full.shape[-1]\n",
    "        y_max_pixel = (y_max+.5) * tm / repr2_full.shape[-2]\n",
    "        dist = ((x_max_pixel - tx)**2 + (y_max_pixel - ty)**2)**0.5\n",
    "        dist_rel = dist / tbb_max\n",
    "        pck = dist_rel <= 0.1\n",
    "        pcks.append(pck)\n",
    "\n",
    "        if not plot:\n",
    "            continue\n",
    "\n",
    "        # setup plot\n",
    "        plt.figure(figsize=(9, 3))\n",
    "        plt.suptitle(f'{sample[\"src_name\"].split(\"/\")[0]} (id:{sample[\"pair_id\"]}) - rel.dist.: {dist_rel:.2f}')\n",
    "\n",
    "        # plot source image\n",
    "        plt.subplot(131)\n",
    "        plt.title('source')\n",
    "        plt.imshow(src_img)\n",
    "        plt.scatter([sx], [sy], c='r')  # source keypoint\n",
    "        plt.plot([sbb[0], sbb[2], sbb[2], sbb[0], sbb[0]], [sbb[1], sbb[1], sbb[3], sbb[3], sbb[1]], c='gray')  # bounding box\n",
    "        plt.axis('off')\n",
    "\n",
    "        # plot target image\n",
    "        plt.subplot(132)\n",
    "        plt.title('target')\n",
    "        plt.imshow(trg_img)\n",
    "        plt.scatter([tx], [ty], c='r')  # target keypoint\n",
    "        plt.plot([tbb[0], tbb[2], tbb[2], tbb[0], tbb[0]], [tbb[1], tbb[1], tbb[3], tbb[3], tbb[1]], c='gray')  # bounding box\n",
    "        plt.axis('off')\n",
    "\n",
    "        # plot similarities\n",
    "        plt.subplot(133)\n",
    "        plt.title('similarities')\n",
    "        plt.imshow(similarities.view(*repr2_full.shape[-2:]).numpy())  # similarities\n",
    "        plt.scatter([x_max], [y_max], c='b')  # predicted keypoint\n",
    "        plt.scatter([tx/tn*repr2_full.shape[-1]-.5], [ty/tm*repr2_full.shape[-2]-.5], c='r')  # true target keypoint\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return pcks\n",
    "\n",
    "\n",
    "def sc_plot_random(\n",
    "        i: int | None = None,\n",
    "        pos: list[str] = ['up_blocks[0]'],\n",
    "        trans: transform_type = None,\n",
    "        step: int = 1,\n",
    "):\n",
    "    if i is None:\n",
    "        i = random.randint(0, len(dataset_pairs)-1)\n",
    "        print(f'{i = }')\n",
    "    transform, transform_keypoint = get_transforms(trans)\n",
    "    sc(dataset_pairs[i], plot=True, extraction_step=step, pos=pos, transform=transform, transform_keypoint=transform_keypoint)\n",
    "\n",
    "\n",
    "def sc_calc_dataset(\n",
    "        pos: list[str] = ['up_blocks[0]'],\n",
    "        trans: transform_type = None,\n",
    "        step: int = 1,\n",
    "    ):\n",
    "    transform, transform_keypoint = get_transforms(trans, size=512)\n",
    "\n",
    "    # precalculate representations\n",
    "    data_dataset = datasets.load_dataset('0jl/SPair-71k', 'data', trust_remote_code=True, split='train')\n",
    "    img_data = [transform(x['img']) for x in tqdm(data_dataset, desc='transforming images')]\n",
    "    prompts = [x['name'].split('/')[0] for x in data_dataset]\n",
    "    dataset_reprs = sd.img2repr(img_data, extract_positions=pos, step=step, prompt=prompts, spatial_avg=False, output_device='cpu')\n",
    "    assert isinstance(dataset_reprs, list)\n",
    "    # dataset_reprs = None\n",
    "\n",
    "    # tp = TrainPlot()\n",
    "    pcks = []\n",
    "    cpcks = {}  # category pcks\n",
    "    pcks_near_edge = []\n",
    "    try:\n",
    "        for sample in tqdm(dataset_pairs, desc='processing samples'):\n",
    "            assert isinstance(sample, dict)\n",
    "            new_pcks = sc(sample, plot=False, precomputed_reprs=dataset_reprs, extraction_step=step, pos=pos, transform=transform, transform_keypoint=transform_keypoint)\n",
    "            pcks += new_pcks\n",
    "            c = dataset_pairs.features['category'].names[sample['category']]\n",
    "            cpcks[c] = cpcks.get(c, []) + new_pcks\n",
    "            n, m = sample['src_img'].size\n",
    "            pcks_near_edge += [x for x, [sx, sy] in zip(new_pcks, sample['src_kps']) if not 16 < sx < n - 16 or not 16 < sy < m - 16]\n",
    "            # tp(**{k: np.mean(v) for k, v in cpcks.items()})\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        print('SC Results:')\n",
    "        print(f'PCK: {np.mean(pcks):5.2%} ({len(pcks)})')\n",
    "        for k, v in cpcks.items():\n",
    "            print(f'{k+\":\":<15} {np.mean(v):5.1%} {f\"({len(v)})\":>7}')\n",
    "        print(f'PCK near edge: {np.mean(pcks_near_edge):5.2%} ({len(pcks_near_edge)})')\n",
    "        return pcks, cpcks\n",
    "\n",
    "\n",
    "def sc_calc_dataset_small(\n",
    "        num_samples=50,\n",
    "        seed=42,\n",
    "        pos: list[str] = ['up_blocks[0]', 'up_blocks[1]'],\n",
    "        trans: transform_type = None,\n",
    "        step: int = 1,\n",
    "    ):\n",
    "    transform, transform_keypoint = get_transforms(trans)\n",
    "    rng = random.Random(seed)\n",
    "\n",
    "    # calculate PCK\n",
    "    pcks = []\n",
    "    for _ in trange(num_samples):\n",
    "        i = rng.randint(0, len(dataset_pairs)-1)\n",
    "        new_pcks = sc(dataset_pairs[i], plot=False, extraction_step=step, pos=pos, transform=transform, transform_keypoint=transform_keypoint)\n",
    "        pcks += new_pcks\n",
    "    print(f'PCK: {np.mean(pcks):5.1%} ({len(pcks)})')\n",
    "\n",
    "\n",
    "\n",
    "def random_hyper_opt():\n",
    "    available_pos = [x for x in sd.available_extract_positions if any(f'{y}_block' in x for y in ['down', 'mid', 'up'])]\n",
    "    runs = []\n",
    "    try:\n",
    "        for _ in trange(int(1e10)):\n",
    "            # randomize hyperparameters\n",
    "            t = ['expand_and_resize', 'expand', None][random.randint(0, 2)]\n",
    "            p = random.sample(available_pos, random.randint(1, len(available_pos)))\n",
    "            s = random.randint(1, 999)\n",
    "\n",
    "            # run\n",
    "            t1, t2 = get_transforms(t)\n",
    "            sample = dataset_pairs[random.randint(0, len(dataset_pairs)-1)]\n",
    "            pcks = sc(sample, plot=False, extraction_step=s, pos=p, transform=t1, transform_keypoint=t2)\n",
    "            for pck in pcks:\n",
    "                runs.append((dict(t=t,p=p,s=s), pck))\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        print('Random Hyperparameter Optimization Results:')\n",
    "        res = np.mean([x[1] for x in runs])\n",
    "        print(f'PCK: {res:.2%} ({len(runs)} runs)')\n",
    "\n",
    "        print('transforms:')\n",
    "        for t in ['expand_and_resize', 'expand', None]:\n",
    "            r = [x[1] for x in runs if x[0][\"t\"] == t]\n",
    "            print(f'  {str(t)+\":\":<20} {np.mean(r):5.1%} ({np.mean(r)-res:+6.1%}) {f\"({len(r)})\":>7}')\n",
    "        \n",
    "        print('positions:')\n",
    "        for p in available_pos:\n",
    "            r = [x[1] for x in runs if p in x[0][\"p\"]]\n",
    "            r_ = [x[1] for x in runs if p not in x[0][\"p\"]]\n",
    "            print(f'  {p+\":\":<20} with: {np.mean(r):5.1%} ({np.mean(r)-res:+6.1%}) {f\"({len(r)})\":>7}, without: {np.mean(r_):.1%} ({np.mean(r_)-res:+6.1%}) {f\"({len(r_)})\":>7}')\n",
    "\n",
    "        print('position combinations: ')\n",
    "        pos_combinations = defaultdict(list)\n",
    "        for x in runs:\n",
    "            pos_combinations[tuple(sorted(x[0][\"p\"]))].append(x[1])\n",
    "        for pos, pck in sorted(pos_combinations.items(), key=lambda x: -np.mean(x[1]))[:20]:\n",
    "            print(f'  {str(pos):50}: {np.mean(pck):5.1%} ({np.mean(pck)-res:+6.1%}) {f\"({len(pck)})\":>7}')\n",
    "\n",
    "        print('steps:')\n",
    "        for s in range(0, 1000, 100):\n",
    "            r = [x[1] for x in runs if s < x[0][\"s\"] <= x[0][\"s\"]+100]\n",
    "            print(f'  {f\"{s}-{s+100}\":20} {np.mean(r):5.1%} ({np.mean(r)-res:+6.1%}) {f\"({len(r)})\":>7}')\n",
    "\n",
    "        return runs\n",
    "\n",
    "# sc_plot_random(pos=['mid_block','up_blocks[0]'], trans='expand_and_resize', step=100)\n",
    "# sc_calc_dataset_small()\n",
    "pcks, cpcks = sc_calc_dataset(pos=['up_blocks[1]'], trans=None, step=100)  # only use trans=None for PCK near edge score\n",
    "# runs = random_hyper_opt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
