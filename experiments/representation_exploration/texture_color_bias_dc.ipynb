{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sdhelper import SD\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from tqdm.autonotebook import tqdm, trange\n",
    "from torch.nn import functional as F\n",
    "import PIL.Image\n",
    "from ipywidgets import interact, FloatSlider, IntSlider\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_subset = load_dataset(\"JonasLoos/imagenet_subset\", split=\"train\")\n",
    "images = [x['image'].convert('RGB') for x in tqdm(imagenet_subset)][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gbr(arr: np.ndarray, interpolation: float):\n",
    "    return arr[:,:,::-1] * interpolation + arr * (1-interpolation)\n",
    "\n",
    "grass_image = np.array(PIL.Image.open('../data/grass.png').convert('RGB'))\n",
    "def add_grass(img: np.ndarray, interpolation: float):\n",
    "    return img * (1-interpolation/2) + grass_image[:img.shape[0],:img.shape[1],:] * interpolation/2\n",
    "\n",
    "knitting_image = np.array(PIL.Image.open('../data/knitting.png').convert('RGB'))\n",
    "def add_knitting(img: np.ndarray, interpolation: float):\n",
    "    return img * (1-interpolation/2) + knitting_image[:img.shape[0],:img.shape[1],:] * interpolation/2\n",
    "\n",
    "def edges_only(arr: np.ndarray, interpolation: float):\n",
    "    gray_tensor = torch.from_numpy(np.dot(arr[...,:3], [0.2989, 0.5870, 0.1140]))[None,None,:,:]  # convert to grayscale\n",
    "    \n",
    "    # Sobel kernels\n",
    "    kx = torch.tensor([[[[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]]], dtype=torch.float64)\n",
    "    ky = torch.tensor([[[[-1, -2, -1], [0, 0, 0], [1, 2, 1]]]], dtype=torch.float64)\n",
    "    \n",
    "    dx = F.conv2d(gray_tensor, kx, padding=1)\n",
    "    dy = F.conv2d(gray_tensor, ky, padding=1)\n",
    "    \n",
    "    edges = torch.sqrt(dx**2 + dy**2)[0,0].numpy()\n",
    "    edges **= .5  # increase sensitivity\n",
    "    edges = (edges / edges.max() * 255).astype(np.uint8)  # normalize\n",
    "    return np.stack([edges] * 3, axis=-1) * interpolation + arr * (1-interpolation)\n",
    "\n",
    "def add_noise(arr: np.ndarray, interpolation: float):\n",
    "    return arr * (1-interpolation/2) + np.random.rand(*arr.shape) * 255 * interpolation/2\n",
    "\n",
    "def blur(arr: np.ndarray, interpolation: float):\n",
    "    return np.array(PIL.Image.fromarray(arr).filter(PIL.ImageFilter.GaussianBlur(radius=16 * interpolation)))\n",
    "\n",
    "conversion_function = add_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_images(interpolation, image_index):\n",
    "    a = np.array(images[image_index])\n",
    "    result = conversion_function(a, interpolation).astype(np.uint8)\n",
    "\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(result)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "interact(\n",
    "    interpolate_images,\n",
    "    interpolation=FloatSlider(min=0, max=1, step=0.01, value=0.5),\n",
    "    image_index=IntSlider(min=0, max=20, step=1, value=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 2))\n",
    "for i, x in enumerate(np.linspace(0, 1, 5)):\n",
    "    arr = np.array(images[0])\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.imshow(conversion_function(arr, x).astype(np.uint8))\n",
    "    plt.title(f'{x:.2f}')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = SD()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_representations = sd.img2repr(images, sd.available_extract_positions, 50, seed=0)\n",
    "representations = []\n",
    "for step in tqdm(np.linspace(0, 1, 5)):\n",
    "    tmp_images = [conversion_function(arr, step).astype(np.uint8) for img in images for arr in [np.array(img)]]\n",
    "    representations.append(sd.img2repr(tmp_images, sd.available_extract_positions, 50, seed=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = np.zeros((len(sd.available_extract_positions), len(representations), len(images)))\n",
    "for block_idx, block in enumerate(tqdm(sd.available_extract_positions)):\n",
    "    for i in trange(len(images)):\n",
    "        a = reference_representations[i].at(block).to('cuda')\n",
    "        for int_idx, bs in enumerate(representations):\n",
    "            b = bs[i].at(block).to('cuda')\n",
    "            sim = a.cosine_similarity(b)\n",
    "            n = sim.shape[0]\n",
    "            accuracy = (sim.view(n*n, n*n).argmax(dim=0) == torch.arange(n*n, device='cuda')).float().mean().cpu()\n",
    "            accuracies[block_idx, int_idx, i] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(8, 6))\n",
    "colors = plt.cm.rainbow(np.linspace(0, 1, len(sd.available_extract_positions)))\n",
    "for block_idx, (block, color) in enumerate(zip(sd.available_extract_positions, colors)):\n",
    "    axs[0].plot(np.linspace(0, 1, len(representations)), accuracies[block_idx].mean(axis=1), label=block, color=color)\n",
    "axs[0].legend(bbox_to_anchor=(1.01, 0.5), loc='center left')\n",
    "axs[0].set_xticklabels([])\n",
    "axs[0].set_ylabel('Accuracy')\n",
    "\n",
    "colors = plt.cm.rainbow(np.linspace(0, 1, len(sd.available_extract_positions)))\n",
    "for block_idx, (block, color) in enumerate(zip(sd.available_extract_positions, colors)):\n",
    "    init_acc = accuracies[block_idx, 0].mean()\n",
    "    acc_change = (accuracies[block_idx].mean(axis=1) - init_acc) / init_acc\n",
    "    axs[1].plot(np.linspace(0, 1, len(representations)), acc_change, label=block, color=color)\n",
    "axs[1].set_xlabel('Interpolation step')\n",
    "axs[1].set_ylabel('Rel. Change in Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
