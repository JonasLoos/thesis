{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the spatial variance/std of representations\n",
    "\n",
    "### problem\n",
    "\n",
    "are the scales of the different representation channels comparable? If not all this might be heavily biased. Analysis shows this is not too bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdhelper import SD\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from PIL import Image\n",
    "import random\n",
    "from tqdm.autonotebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def concat_reprs(reprs: dict[str, torch.Tensor], pos: list[str]):\n",
    "    '''Concatenate representations with different spatial sizes into a single tensor with the largest spatial size.'''\n",
    "    # If the representation sizes are not multiples of each other, the bottom and right edges of the spatially larger representations will be 0-padded.\n",
    "    max_spatial = np.array(max(reprs[x].shape[-2:] for x in pos))\n",
    "    min_spatial = np.array(min(reprs[x].shape[-2:] for x in pos))\n",
    "    while (max_spatial > min_spatial).any(): min_spatial *= 2\n",
    "    spatial = min_spatial\n",
    "    num_features1 = sum(reprs[x].shape[1] for x in pos)\n",
    "    repr_full = torch.zeros((num_features1, *spatial))\n",
    "    i = 0\n",
    "    for p in pos:\n",
    "        r1 = reprs[p]\n",
    "        _, num_channels1, n1, m1 = r1.shape\n",
    "        tmp1 = r1.repeat_interleave(spatial[0]//n1, dim=-2).repeat_interleave(spatial[1]//m1, dim=-1)\n",
    "        repr_full[i:i+num_channels1, :tmp1.shape[-2], :tmp1.shape[-1]] = tmp1\n",
    "        i += num_channels1\n",
    "    return repr_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = SD('sdxl-turbo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean representation values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = sd('a cat', extract_positions=['mid_block'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mean repr value during generation:', res.representations['mid_block'][-1].abs().mean().item())\n",
    "print(f'mean repr value during extraction', sd.img2repr(res.result_image, ['mid_block'], i)['mid_block'].abs().mean().item())  # timestep 0 is different from the last generation step\n",
    "\n",
    "for i in range(0, 501,50):\n",
    "    repr = sd.img2repr(res.result_image, ['mid_block'], i)['mid_block']\n",
    "    plt.plot(sorted(repr.abs().mean(dim=(0,2,3)), reverse=True), label=f'step {i}')\n",
    "plt.xlabel('channel (sorted by mean absolute value)')\n",
    "plt.ylabel('mean absolute value')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# binning on logaritmic scale\n",
    "repr = sd.img2repr(res.result_image, ['mid_block'], 100)['mid_block']\n",
    "repr = repr.abs().mean(dim=(0,2,3))\n",
    "plt.hist(repr, bins=np.logspace(np.log10(repr.min()), np.log10(repr.max()), 50))\n",
    "plt.xscale('log')\n",
    "plt.xlabel('mean absolute value')\n",
    "plt.ylabel('number of channels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dispersion of representation values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_std(\n",
    "        img: Image.Image,\n",
    "        pos: list[str],\n",
    "        num_samples: int,\n",
    "        step: int = 50,\n",
    "):\n",
    "    reprs = torch.stack([concat_reprs(sd.img2repr(img, pos, step), pos) for _ in trange(num_samples)])\n",
    "    std = reprs.std(dim=0).mean(dim=0)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title('Input image')\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(f'Standard deviation (mean: +-{std.mean().item():.2f})')\n",
    "    plt.imshow(std.cpu().numpy(), vmin=0, vmax=4, cmap='hot')\n",
    "    plt.show()\n",
    "\n",
    "for i in range(5):\n",
    "    plot_std(sd('a cat').result_image, ['mid_block'], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = ['up_blocks[1]']\n",
    "img = sd('a cat').result_image\n",
    "\n",
    "stds = []\n",
    "for timestep in tqdm(range(0, 251, 50)):\n",
    "    reprs = torch.stack([concat_reprs(sd.img2repr(img, pos, timestep), pos) for _ in range(100)])\n",
    "    std = reprs.std(dim=0).mean()\n",
    "    stds.append(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0, 251, 50), stds)\n",
    "plt.xlabel('Timestep')\n",
    "plt.ylabel('Mean standard deviation')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
